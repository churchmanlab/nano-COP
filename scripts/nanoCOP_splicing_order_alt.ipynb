{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Date : August 1, 2019\n",
    "\n",
    "Author : Heather Landry Drexler\n",
    "\n",
    "This script will develop datasets for splicing order plots\n",
    "for alternative introns. These files serve as input for the scripts for\n",
    "Figure 5I.\n",
    "                          \n",
    "                                            \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pysam\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "% matplotlib inline\n",
    "\n",
    "import math\n",
    "\n",
    "import pybedtools\n",
    "from pybedtools import BedTool\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeChrom(row):\n",
    "    chrom = row['chrom'][3:]\n",
    "    return chrom\n",
    "\n",
    "# function to get a bedtool file with splice site info from dm6 intron coordinate bed file\n",
    "def hg38_introns_byRow(row):\n",
    "\n",
    "    chrom = row['chrom'][3:]\n",
    "    start = row['start']\n",
    "    end = row['end']\n",
    "    name_split = row['name'].split('_intron')\n",
    "    gene = name_split[0] \n",
    "    feature = name_split[1].split('_')[1] # intron_count\n",
    "    strand = row['strand']\n",
    "    alt_refseq = row['alternative_gtf']\n",
    "    SE = row['SE_MISO']\n",
    "    SE_PSI = row['PSI_SE']\n",
    "    A5SS = row['A5SS_MISO']\n",
    "    A5SS_PSI = row['PSI_A5SS']\n",
    "    A3SS = row['A3SS_MISO']\n",
    "    A3SS_PSI = row['PSI_A3SS']\n",
    "    MXE = row['MXE_MISO']\n",
    "    MXE_PSI = row['PSI_MXE']\n",
    "        \n",
    "    # Make a single column for classification of alternative introns\n",
    "    alt_events = []\n",
    "        \n",
    "    if (SE == 'YES' or A5SS == 'YES' or A3SS == 'YES' or MXE == 'YES'):\n",
    "        if (SE_PSI > 0.8 or A5SS_PSI > 0.8 or A3SS_PSI > 0.8 or MXE_PSI > 0.8):\n",
    "            return 'ALT'\n",
    "        elif (SE_PSI > 0.2 or A5SS_PSI > 0.2 or A3SS_PSI > 0.2 or MXE_PSI > 0.2):\n",
    "            return 'PARTIAL'\n",
    "        else:\n",
    "            return 'OTHER'              \n",
    "    elif (SE == 'NO' and A5SS == 'NO' and A3SS == 'NO' and MXE == 'NO'):\n",
    "        return 'CONST'                               \n",
    "    else:\n",
    "        return 'OTHER'\n",
    "\n",
    "\n",
    "# function to create a dataframe with reads that span 3'SS positions\n",
    "def get_intron_intersect(introns_df, bam_file):\n",
    "    # get reads that span 3' splice sites and convert to a dataframe\n",
    "    bedFile = bam_file.bam_to_bed(cigar=True, tag='NM') # convert bam file to bed file, keep cigar string and NM (edit distance) tag\n",
    "    intersect = bedFile.intersect(introns_df, wo=True, s=True) # intersect reads from bam file with 3' splice site coordinates, ensure strandedness\n",
    "    df = intersect.to_dataframe(names=['chr_aln', 'start_aln', 'end_aln', 'name_aln', 'qual_aln', \\\n",
    "                                           'strand_aln', 'cigar_aln', 'chr_intron', 'start_intron', \\\n",
    "                                           'end_intron', 'name_gene', 'intron_count', 'strand_gene', 'alt_refseq', \\\n",
    "                                       'alt_events', 'count'], \\\n",
    "                               dtype={\"chr_aln\": str, \"start_aln\": int, \"end_aln\": int, \\\n",
    "                                     \"name_aln\": str, \"qual_aln\": int, \"strand_aln\": str, \\\n",
    "                                     \"cigar_aln\": str, \"chr_intron\": str, \"start_intron\": int, \\\n",
    "                                     \"end_intron\": int, \"name_gene\": str, \\\n",
    "                                     \"intron_count\": int,\"strand_gene\": str, \\\n",
    "                                      \"alt_refseq\": str, \"alt_events\": str, \\\n",
    "                                      \"count\": int}) # convert to a dataframe\n",
    "    return df\n",
    "\n",
    "\n",
    "# function to create a dataframe with splicing information for\n",
    "# every read that spans an intron in the dataset\n",
    "def get_splicing_info(intersect_df, min_overlap):\n",
    "    \n",
    "    df = intersect_df\n",
    "\n",
    "    # prepare a list for splice calls\n",
    "    spliceCalls = []\n",
    "\n",
    "    # set variables for parsing the cigar string\n",
    "    pattern = re.compile('([MIDNSHPX=])')\n",
    "    Consumes_Query = [\"M\", \"I\", \"S\", \"=\", \"X\"]\n",
    "    Consumes_Reference = [\"M\", \"D\", \"N\", \"=\", \"X\"]    \n",
    "\n",
    "    # loop through all read-intron intersects\n",
    "    for i in range(0,df.shape[0]):\n",
    "\n",
    "        # ignore reads that do not overlap intron by minimum threshold\n",
    "        if (df['count'].iloc[i] < min_overlap):\n",
    "            continue\n",
    "\n",
    "        # record the start and ends of reads \n",
    "        # will deal with gene strand after cigar counts are made\n",
    "        aln_start = df['start_aln'].iloc[i] # record the start of the read\n",
    "        aln_end = df['end_aln'].iloc[i] # record the end of the read\n",
    "        intron_start = df['start_intron'].iloc[i] # record the end of the intron\n",
    "        intron_end = df['end_intron'].iloc[i] # record the end of the intron\n",
    "\n",
    "        # parse cigar string into a list of tuples for easy parsing\n",
    "        Sep_Values = pattern.split(df['cigar_aln'].iloc[i])[:-1]\n",
    "        CigarPairs = list((Sep_Values[n:n+2] for n in range(0, len(Sep_Values), 2)))  \n",
    "\n",
    "        # set up variables for measuring the length of cigar string operators\n",
    "        CigarOp_counts = {'M': 0, 'I': 0, 'D': 0, 'N': 0, 'S': 0, 'H': 0, 'P': 0, '=': 0, 'X': 0}\n",
    "        start_counts = {'M': 0, 'I': 0, 'D': 0, 'N': 0, 'S': 0, 'H': 0, 'P': 0, '=': 0, 'X': 0}\n",
    "        end_counts = {'M': 0, 'I': 0, 'D': 0, 'N': 0, 'S': 0, 'H': 0, 'P': 0, '=': 0, 'X': 0}\n",
    "        intron_counts = {'M': 0, 'I': 0, 'D': 0, 'N': 0, 'S': 0, 'H': 0, 'P': 0, '=': 0, 'X': 0}\n",
    "        currentloc = int(df['start_aln'].iloc[i])\n",
    "\n",
    "        # go through list of cigar strings and grab splicing information\n",
    "        for cigar_Entry in CigarPairs:\n",
    "\n",
    "            op_Length = int(cigar_Entry[0]) # get length of cigar operator\n",
    "            cigarOp = cigar_Entry[1] # get type of cigar operator  \n",
    "            CigarOp_counts[cigarOp] += op_Length # add the cigar operator length to the counts dictionary\n",
    "            cigarOp_start=currentloc # get the starting coordinate of the cigar operator\n",
    "\n",
    "            if (cigarOp in Consumes_Reference):\n",
    "                currentloc=currentloc+op_Length # add the cigar operator length to the current location coordinate \n",
    "\n",
    "            cigarOp_end=currentloc # get the ending coordinate of the cigar operator\n",
    "\n",
    "            # gather information if the portion of the cigar string spans the designated intron start\n",
    "            if (cigarOp_start<intron_start-min_overlap and cigarOp_end>=intron_start-min_overlap):\n",
    "                if (cigarOp_end>=intron_start+min_overlap):\n",
    "                    count=min_overlap*2\n",
    "                else:\n",
    "                    count=cigarOp_end-(intron_start-min_overlap)+1\n",
    "                start_counts[cigarOp] += count # add the cigar operator length to the counts dictionary\n",
    "\n",
    "            elif (cigarOp_start>=intron_start-min_overlap and cigarOp_end<intron_start+min_overlap):\n",
    "                count=op_Length\n",
    "                start_counts[cigarOp] += count # add the cigar operator length to the counts dictionary       \n",
    "\n",
    "            elif (cigarOp_start<intron_start+min_overlap and cigarOp_end>=intron_start+min_overlap):\n",
    "                if (cigarOp_start<=intron_start-min_overlap):\n",
    "                    count=min_overlap*2\n",
    "                else:\n",
    "                    count=(intron_start+min_overlap)-cigarOp_start-1\n",
    "                start_counts[cigarOp] += count # add the cigar operator length to the counts dictionary \n",
    "\n",
    "            # gather information if the portion of the cigar string is within the intron\n",
    "            if (cigarOp_start<intron_start and cigarOp_end>=intron_start):\n",
    "                if (cigarOp_end>=intron_end):\n",
    "                    count=intron_end-intron_start\n",
    "                else:\n",
    "                    count=cigarOp_end-intron_start\n",
    "                intron_counts[cigarOp] += count # add the cigar operator length to the counts dictionary\n",
    "\n",
    "            elif (cigarOp_start>=intron_start and cigarOp_end<intron_end):\n",
    "                count=op_Length\n",
    "                intron_counts[cigarOp] += count # add the cigar operator length to the counts dictionary\n",
    "\n",
    "            elif (cigarOp_start<intron_end and cigarOp_end>=intron_end):\n",
    "                if (cigarOp_start<=intron_start):\n",
    "                    count=intron_end-intron_start\n",
    "                else:\n",
    "                    count=intron_end-cigarOp_start\n",
    "                intron_counts[cigarOp] += count # add the cigar operator length to the counts dictionary \n",
    "\n",
    "            # gather information if the portion of the cigar string spans the designated intron end\n",
    "            if (cigarOp_start<intron_end-min_overlap and cigarOp_end>=intron_end-min_overlap):\n",
    "                if (cigarOp_end>=intron_end+min_overlap):\n",
    "                    count=min_overlap*2\n",
    "                else:\n",
    "                    count=cigarOp_end-(intron_end-min_overlap)\n",
    "                end_counts[cigarOp] += count # add the cigar operator length to the counts dictionary\n",
    "\n",
    "            elif (cigarOp_start>=intron_end-min_overlap and cigarOp_end<intron_end+min_overlap):\n",
    "                count=op_Length\n",
    "                end_counts[cigarOp] += count # add the cigar operator length to the counts dictionary\n",
    "\n",
    "            elif (cigarOp_start<intron_end+min_overlap and cigarOp_end>=intron_end+min_overlap):\n",
    "                if (cigarOp_start<=intron_end-min_overlap):\n",
    "                    count=min_overlap*2\n",
    "                else:\n",
    "                    count=(intron_end+min_overlap)-cigarOp_start\n",
    "                end_counts[cigarOp] += count # add the cigar operator length to the counts dictionary \n",
    "\n",
    "        # get length of the aligned portion of this read from cigar string\n",
    "        aligned_read_length = CigarOp_counts['M']+CigarOp_counts['D']\n",
    "\n",
    "        # get 5'SS and 3'SS counts as determined by gene strand\n",
    "        strand = df['strand_gene'].iloc[i]\n",
    "        if (strand == '+'):\n",
    "            aln_start = df['start_aln'].iloc[i] # record the start of the read\n",
    "            aln_end = df['end_aln'].iloc[i] # record the end of the read\n",
    "            intron_5SS_counts = start_counts # record the cigar string counts over the 5'SS\n",
    "            intron_3SS_counts = end_counts # record the cigar string counts over the 3'SS\n",
    "            read_overlap = intron_end - (aln_end - aligned_read_length + min_overlap)\n",
    "            \n",
    "        if (strand == '-'):\n",
    "            aln_start = df['end_aln'].iloc[i] # record the start of the read\n",
    "            aln_end = df['start_aln'].iloc[i] # record the end of the read\n",
    "            intron_5SS_counts = end_counts # record the cigar string counts over the 5'SS\n",
    "            intron_3SS_counts = start_counts # record the cigar string counts over the 3'SS  \n",
    "            read_overlap = (aln_end + aligned_read_length - min_overlap) - intron_start\n",
    "            \n",
    "        # annotate splicing status based on CIGAR string information around splice sites\n",
    "        splice='UNDETERMINED'\n",
    "\n",
    "        if (intron_5SS_counts['N']==0 and intron_3SS_counts['N']==0):\n",
    "            if (intron_3SS_counts['M']+intron_3SS_counts['D']==min_overlap*2):\n",
    "                if (intron_3SS_counts['M']>min_overlap):\n",
    "                    splice = 'NO'\n",
    "\n",
    "        if (intron_5SS_counts['N']>0 and intron_5SS_counts['N']<min_overlap*2):\n",
    "            if (intron_3SS_counts['N']>0 and intron_3SS_counts['N']<min_overlap*2):\n",
    "                splice = 'YES'\n",
    "\n",
    "        # annotate splicing status based on CIGAR string information within the intron \n",
    "        if (splice == 'YES'):\n",
    "            if (float(intron_end-intron_start) > 0.0):\n",
    "                ratio = float(intron_counts['N'])/float(intron_end-intron_start)\n",
    "                difference = abs(intron_counts['N']-(intron_end-intron_start))\n",
    "\n",
    "                # if read is spliced, between 90-100% of the intron has to be spliced \n",
    "                # and no more than 100 nucleotides within the intron can be matching the intron sequence\n",
    "                # change this to no more than 10 nucleotides for alternative splicing analysis\n",
    "                if( ratio < 0.9 or ratio > 1.1 or difference > 10):\n",
    "                    splice='UNDETERMINED'\n",
    "            if (float(intron_end-intron_start) == 0.0):\n",
    "                splice='UNDETERMINED'\n",
    "\n",
    "        if (splice == 'NO'):\n",
    "            if (float(intron_end-intron_start) > 0.0):\n",
    "                ratio = float(intron_counts['M'])/(float(intron_counts['M'])+float(intron_counts['N'])+float(intron_counts['D'])+1)\n",
    "\n",
    "                # if read is unspliced, at least 75% of the read has to match (CIGAR=M) the intron sequence\n",
    "                if(intron_counts['M'] < min_overlap/2 or ratio < 0.75):\n",
    "                    splice='UNDETERMINED'\n",
    "            \n",
    "            if (float(intron_end-intron_start) == 0.0):\n",
    "                splice='UNDETERMINED'\n",
    "\n",
    "        # save read, intron, and splicing information\n",
    "        spliceCalls.append([df['name_aln'].iloc[i],df['chr_intron'].iloc[i],intron_start,intron_end,df['strand_gene'].iloc[i],df['name_gene'].iloc[i],df['intron_count'].iloc[i],read_overlap,splice,\n",
    "                           df['alt_refseq'].iloc[i],df['alt_events'].iloc[i]])  \n",
    "\n",
    "    spliceCalls_df = pd.DataFrame(spliceCalls)\n",
    "    spliceCalls_df.columns = [\"read_name\",\"chrom\",\"intron_start\",\"intron_end\",\"strand\",\"gene_name\",\"intron_count\",\"read_overlap\",\"splice_status\",\n",
    "                             \"alt_refseq\", \"alt_events\"]\n",
    "\n",
    "    return spliceCalls_df\n",
    "\n",
    "\n",
    "\n",
    "# every read that spans an intron in the dataset\n",
    "def get_read_junctions_dictionary(splice_df):\n",
    "\n",
    "    read_junctions = {}\n",
    "\n",
    "    for i in range(0,splice_df.shape[0]):       \n",
    "\n",
    "        # define the read name\n",
    "        read_name = splice_df['read_name'].iloc[i]\n",
    "        gene_name = splice_df['gene_name'].iloc[i]\n",
    "        chrom = splice_df['chrom'].iloc[i]\n",
    "        intron_start = splice_df['intron_start'].iloc[i]\n",
    "        intron_end = splice_df['intron_end'].iloc[i]\n",
    "        intron_count = splice_df['intron_count'].iloc[i]\n",
    "        strand = splice_df['strand'].iloc[i]\n",
    "        read_overlap = splice_df['read_overlap'].iloc[i]\n",
    "        splice_status = splice_df['splice_status'].iloc[i]\n",
    "        alt_refseq = splice_df['alt_refseq'].iloc[i]\n",
    "        alt_events = splice_df['alt_events'].iloc[i]\n",
    "\n",
    "        # check if read name is in the dictionary, if not save it\n",
    "        if read_name not in read_junctions.keys():\n",
    "\n",
    "            # make a new dictionary for the gene and add intron info to it\n",
    "            read_junctions[read_name] = {}\n",
    "            read_junctions[read_name][gene_name] = [[chrom, intron_start, intron_end, intron_count, strand, read_overlap, splice_status,\n",
    "                                                    alt_refseq, alt_events]]\n",
    "\n",
    "        # check if read name is in the dictionary, if it is proceed to gene information\n",
    "        elif read_name in read_junctions.keys():\n",
    "\n",
    "            # if gene_name is not already in read dictionary, \n",
    "            # make a new dictionary for the gene and add intron info to it\n",
    "            if gene_name not in read_junctions[read_name].keys():\n",
    "                read_junctions[read_name][gene_name] = [[chrom, intron_start, intron_end, intron_count, strand, read_overlap, splice_status,\n",
    "                                                        alt_refseq, alt_events]]\n",
    "\n",
    "            # if gene_name is already in read dictionary, add new intron info to it\n",
    "            elif gene_name in read_junctions[read_name].keys():\n",
    "                read_junctions[read_name][gene_name].append([chrom, intron_start, intron_end, intron_count, strand, read_overlap, splice_status,\n",
    "                                                            alt_refseq, alt_events])\n",
    "\n",
    "    return read_junctions\n",
    "\n",
    "\n",
    "def get_intron_distribution(read_junctions):\n",
    "\n",
    "    intron_distribution = []\n",
    "\n",
    "    for read in read_junctions.keys():\n",
    "\n",
    "        read_distribution = []\n",
    "\n",
    "        for gene in read_junctions[read].keys():\n",
    "\n",
    "            if (len(read_junctions[read][gene]) > 1):\n",
    "\n",
    "                splice_status = [row[6] for row in read_junctions[read][gene]]\n",
    "                status_count = Counter(splice_status)\n",
    "\n",
    "                spliced_count = status_count['YES']\n",
    "                unspliced_count = status_count['NO']\n",
    "\n",
    "                if (unspliced_count == 0 and spliced_count > 1):\n",
    "                    read_distribution.append([read,gene,'all_spliced'])\n",
    "\n",
    "                elif (unspliced_count > 1 and spliced_count == 0):\n",
    "                    read_distribution.append([read,gene,'all_unspliced'])\n",
    "\n",
    "                elif (unspliced_count > 0 and spliced_count > 0):\n",
    "                    read_distribution.append([read,gene,'intermediate'])\n",
    "\n",
    "            if (len(read_junctions[read]) == len(read_distribution)):\n",
    "                if (len(read_junctions[read]) == 1):\n",
    "                    intron_distribution.append([read,read_distribution[0][2]])\n",
    "\n",
    "                if (len(read_junctions[read]) > 1):\n",
    "                    read_distribution_df = pd.DataFrame(read_distribution)\n",
    "                    read_distribution_df.columns = ['read','gene','distribution'] \n",
    "                    distribution_count = Counter(read_distribution_df['distribution'])\n",
    "\n",
    "                    if (len(distribution_count) == 1):\n",
    "                        intron_distribution.append([read,list(distribution_count.keys())[0]])\n",
    "\n",
    "    intron_distribution_df = pd.DataFrame(intron_distribution)\n",
    "    intron_distribution_df.columns = ['read','distribution']        \n",
    "\n",
    "    return intron_distribution_df\n",
    "\n",
    "\n",
    "def get_pie_chart_df(intron_distribution_df):\n",
    "    \n",
    "    pie_chart = []\n",
    "    \n",
    "    pie_chart.append(['all_unspliced',len(intron_distribution_df[intron_distribution_df['distribution']=='all_unspliced'])])\n",
    "    pie_chart.append(['all_spliced',len(intron_distribution_df[intron_distribution_df['distribution']=='all_spliced'])])\n",
    "    pie_chart.append(['intermediate',len(intron_distribution_df[intron_distribution_df['distribution']=='intermediate'])])\n",
    "    pie_chart_df = pd.DataFrame(pie_chart)\n",
    "    pie_chart_df = pie_chart_df.set_index([0])\n",
    "    pie_chart_df.columns = ['count']\n",
    "    \n",
    "    return pie_chart_df\n",
    "\n",
    "\n",
    "def get_intron_pairs_df(read_junctions, good_events):\n",
    "    # good_events are the events that should be considered alternative below\n",
    "    \n",
    "    intron_pairs = []\n",
    "\n",
    "    # loop through all reads in the dictionary\n",
    "    for read in read_junctions.keys():\n",
    "\n",
    "        # make a set for all intron pairs within a read\n",
    "        # this will avoid duplicate pairs being called due to alternative splicing\n",
    "        uniq_pairs = set()\n",
    "        uniq_splice_pattern = set()\n",
    "        \n",
    "        # loop through all genes that has introns that a read maps to\n",
    "        for gene in read_junctions[read].keys():\n",
    "\n",
    "            # only go through genes that have 2 or more introns\n",
    "            if (len(read_junctions[read][gene]) > 1 ):\n",
    "\n",
    "                # characterize the number of spliced and unspliced introns in the read\n",
    "                splice_status = [row[6] for row in read_junctions[read][gene]]\n",
    "                splice_status_join = '_'.join(splice_status)\n",
    "                status_count = Counter(splice_status)\n",
    "                 \n",
    "                # only process the file if intron pattern hasn't been seen previously\n",
    "                # for a gene that this read aligns to\n",
    "                if (splice_status_join not in uniq_splice_pattern):\n",
    "                    uniq_splice_pattern.add(splice_status_join)\n",
    "\n",
    "                    spliced_count = status_count['YES']\n",
    "                    unspliced_count = status_count['NO']\n",
    "\n",
    "                    # build a dataframe of introns in the gene that map to this read\n",
    "                    # and are capable of being sequenced if the read has no splicing\n",
    "                    read_introns_df = pd.DataFrame(read_junctions[read][gene])\n",
    "                    read_introns_df.columns = ['chrom','start','end','intron_count','strand','read_overlap','splice_status', 'alt_refseq', 'alt_events']\n",
    "                    read_introns_df = read_introns_df[read_introns_df['read_overlap'] > 0].sort_values('intron_count').reset_index(drop=True)\n",
    "\n",
    "                    # loop through introns that read maps to and find pairs\n",
    "                    prev_intron_count = -2    # counter for the start becuase no intron should have a negative count\n",
    "                    \n",
    "\n",
    "                    for i in range(len(read_introns_df)):\n",
    "                        intron_count = read_introns_df.iloc[i]['intron_count']\n",
    "                        intron_chrom = str(read_introns_df.iloc[i]['chrom'])\n",
    "                        intron_start = str(read_introns_df.iloc[i]['start'])\n",
    "                        intron_end = str(read_introns_df.iloc[i]['end'])\n",
    "                        intron_strand = read_introns_df.iloc[i]['strand']\n",
    "                        intron_splice = read_introns_df.iloc[i]['splice_status']\n",
    "                        intron_alt_refseq = read_introns_df.iloc[i]['alt_refseq']\n",
    "                        intron_alt_events = read_introns_df.iloc[i]['alt_events']\n",
    "                        intron_coord = intron_chrom+'_'+intron_start+'_'+intron_end\n",
    "                        \n",
    "                        # determine if the intron is alternative or constitutive based on those three columns\n",
    "                        if intron_alt_events == 'CONST':\n",
    "                            intron_alt = 'constitutive'\n",
    "                            \n",
    "                        elif intron_alt_events in good_events:\n",
    "                            intron_alt = 'alternative'\n",
    "                                \n",
    "                        else:\n",
    "                            intron_alt = 'other'\n",
    "\n",
    "                        # if intron counts are sequential (one follows the next)\n",
    "                        # it is a true intron pair (i.e. neighboring introns)\n",
    "                        if (intron_count - prev_intron_count == 1):\n",
    "                            intron_pair_coord = prev_intron_coord+'_'+intron_coord\n",
    "\n",
    "                            # record information about the read pair only if the coordinates of this\n",
    "                            # intron pair have not yet been seen\n",
    "                            if (intron_pair_coord not in uniq_pairs): \n",
    "                                uniq_pairs.add(intron_pair_coord)\n",
    "                                prev_intron_start = prev_intron_coord.split('_')[1]\n",
    "                                prev_intron_end = prev_intron_coord.split('_')[2]\n",
    "\n",
    "                                # append intron pair coordinate and splicing information to a list\n",
    "                                intron_pairs.append([read,intron_chrom,prev_intron_start,prev_intron_end,\n",
    "                                                     int(intron_start),int(intron_end),intron_strand,\n",
    "                                                    prev_intron_splice, intron_splice, prev_intron_alt, intron_alt])\n",
    "\n",
    "                        # save information about this intron for the next pair\n",
    "                        prev_intron_count = intron_count\n",
    "                        prev_intron_coord = intron_coord\n",
    "                        prev_intron_splice = intron_splice\n",
    "                        prev_intron_alt = intron_alt\n",
    "\n",
    "    intron_pairs_df = pd.DataFrame(intron_pairs)\n",
    "    intron_pairs_df.columns = ['read','chrom','int1_start','int1_end','int2_start','int2_end','strand','int1_splice','int2_splice',\n",
    "                              'int1_alt', 'int2_alt']        \n",
    "\n",
    "    return intron_pairs_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_splicing_order_df(intron_pairs_df):\n",
    "    \n",
    "    splicing_order = []\n",
    "\n",
    "    pos_1st = len(intron_pairs_df[(intron_pairs_df['strand']==\"+\") & (intron_pairs_df['int1_splice']==\"YES\") & (intron_pairs_df['int2_splice']==\"NO\")])\n",
    "    pos_2nd = len(intron_pairs_df[(intron_pairs_df['strand']==\"+\") & (intron_pairs_df['int1_splice']==\"NO\") & (intron_pairs_df['int2_splice']==\"YES\")])\n",
    "\n",
    "    neg_1st = len(intron_pairs_df[(intron_pairs_df['strand']==\"-\") & (intron_pairs_df['int1_splice']==\"NO\") & (intron_pairs_df['int2_splice']==\"YES\")])\n",
    "    neg_2nd = len(intron_pairs_df[(intron_pairs_df['strand']==\"-\") & (intron_pairs_df['int1_splice']==\"YES\") & (intron_pairs_df['int2_splice']==\"NO\")])\n",
    "\n",
    "    all_yes = len(intron_pairs_df[(intron_pairs_df['int1_splice']==\"YES\") & (intron_pairs_df['int2_splice']==\"YES\")])\n",
    "    all_no = len(intron_pairs_df[(intron_pairs_df['int1_splice']==\"NO\") & (intron_pairs_df['int2_splice']==\"NO\")])\n",
    "    \n",
    "    all_1st = pos_1st + neg_1st\n",
    "    all_2nd = pos_2nd + neg_2nd\n",
    "    percent_1st = float(all_1st) / float(all_1st + all_2nd) * 100.0\n",
    "\n",
    "    splicing_order.append([all_yes,all_1st,all_2nd,all_no,percent_1st])\n",
    "\n",
    "    splicing_order_df = pd.DataFrame(splicing_order)\n",
    "    splicing_order_df.columns = ['yes_yes','yes_no','no_yes','no_no','percent_first']\n",
    "\n",
    "    return splicing_order_df\n",
    "\n",
    "\n",
    "# Same function as above, but applied to pairs of adjacent constitutive/alternative intron pairs\n",
    "# Determines which intron gets spliced first and which gets transcribed first\n",
    "\n",
    "def get_splicing_order_df_alt(intron_pairs_df):\n",
    "    \n",
    "    splicing_order = []\n",
    "    splicing_order_percent = []\n",
    "    \n",
    "    pos_const_txn_1st_spliced_1st = len(intron_pairs_df[(intron_pairs_df['strand']==\"+\") &\n",
    "                                                        (intron_pairs_df['int1_splice'] == \"YES\") &\n",
    "                                                   (intron_pairs_df['int2_splice'] == \"NO\") &\n",
    "                                                   (intron_pairs_df['int1_alt'] == \"constitutive\") &\n",
    "                                                   (intron_pairs_df['int2_alt'] == \"alternative\")])\n",
    "    \n",
    "    neg_const_txn_1st_spliced_1st = len(intron_pairs_df[(intron_pairs_df['strand']==\"-\") &\n",
    "                                                        (intron_pairs_df['int1_splice'] == \"NO\") &\n",
    "                                                   (intron_pairs_df['int2_splice'] == \"YES\") &\n",
    "                                                   (intron_pairs_df['int1_alt'] == \"alternative\") &\n",
    "                                                   (intron_pairs_df['int2_alt'] == \"constitutive\")])\n",
    "    \n",
    "    pos_const_txn_1st_spliced_2nd = len(intron_pairs_df[(intron_pairs_df['strand']==\"+\") &\n",
    "                                                        (intron_pairs_df['int1_splice'] == \"NO\") &\n",
    "                                                   (intron_pairs_df['int2_splice'] == \"YES\") &\n",
    "                                                   (intron_pairs_df['int1_alt'] == \"constitutive\") &\n",
    "                                                   (intron_pairs_df['int2_alt'] == \"alternative\")])\n",
    "    \n",
    "    neg_const_txn_1st_spliced_2nd = len(intron_pairs_df[(intron_pairs_df['strand']==\"-\") &\n",
    "                                                        (intron_pairs_df['int1_splice'] == \"YES\") &\n",
    "                                                   (intron_pairs_df['int2_splice'] == \"NO\") &\n",
    "                                                   (intron_pairs_df['int1_alt'] == \"alternative\") &\n",
    "                                                   (intron_pairs_df['int2_alt'] == \"constitutive\")])\n",
    "    \n",
    "    #####\n",
    "    \n",
    "    pos_alt_txn_1st_spliced_1st = len(intron_pairs_df[(intron_pairs_df['strand']==\"+\") &\n",
    "                                                        (intron_pairs_df['int1_splice'] == \"YES\") &\n",
    "                                                   (intron_pairs_df['int2_splice'] == \"NO\") &\n",
    "                                                   (intron_pairs_df['int1_alt'] == \"alternative\") &\n",
    "                                                   (intron_pairs_df['int2_alt'] == \"constitutive\")])\n",
    "    \n",
    "    neg_alt_txn_1st_spliced_1st = len(intron_pairs_df[(intron_pairs_df['strand']==\"-\") &\n",
    "                                                        (intron_pairs_df['int1_splice'] == \"NO\") &\n",
    "                                                   (intron_pairs_df['int2_splice'] == \"YES\") &\n",
    "                                                   (intron_pairs_df['int1_alt'] == \"constitutive\") &\n",
    "                                                   (intron_pairs_df['int2_alt'] == \"alternative\")])\n",
    "    \n",
    "    pos_alt_txn_1st_spliced_2nd = len(intron_pairs_df[(intron_pairs_df['strand']==\"+\") &\n",
    "                                                        (intron_pairs_df['int1_splice'] == \"NO\") &\n",
    "                                                   (intron_pairs_df['int2_splice'] == \"YES\") &\n",
    "                                                   (intron_pairs_df['int1_alt'] == \"alternative\") &\n",
    "                                                   (intron_pairs_df['int2_alt'] == \"constitutive\")])\n",
    "    \n",
    "    neg_alt_txn_1st_spliced_2nd = len(intron_pairs_df[(intron_pairs_df['strand']==\"-\") &\n",
    "                                                        (intron_pairs_df['int1_splice'] == \"YES\") &\n",
    "                                                   (intron_pairs_df['int2_splice'] == \"NO\") &\n",
    "                                                   (intron_pairs_df['int1_alt'] == \"constitutive\") &\n",
    "                                                   (intron_pairs_df['int2_alt'] == \"alternative\")])\n",
    "    \n",
    "    #####\n",
    "    \n",
    "    pos_2const_txn_1st_spliced_1st = len(intron_pairs_df[(intron_pairs_df['strand']==\"+\") &\n",
    "                                                        (intron_pairs_df['int1_splice'] == \"YES\") &\n",
    "                                                   (intron_pairs_df['int2_splice'] == \"NO\") &\n",
    "                                                   (intron_pairs_df['int1_alt'] == \"constitutive\") &\n",
    "                                                   (intron_pairs_df['int2_alt'] == \"constitutive\")])\n",
    "    \n",
    "    neg_2const_txn_1st_spliced_1st = len(intron_pairs_df[(intron_pairs_df['strand']==\"-\") &\n",
    "                                                        (intron_pairs_df['int1_splice'] == \"NO\") &\n",
    "                                                   (intron_pairs_df['int2_splice'] == \"YES\") &\n",
    "                                                   (intron_pairs_df['int1_alt'] == \"constitutive\") &\n",
    "                                                   (intron_pairs_df['int2_alt'] == \"constitutive\")])\n",
    "    \n",
    "    pos_2const_txn_1st_spliced_2nd = len(intron_pairs_df[(intron_pairs_df['strand']==\"+\") &\n",
    "                                                        (intron_pairs_df['int1_splice'] == \"NO\") &\n",
    "                                                   (intron_pairs_df['int2_splice'] == \"YES\") &\n",
    "                                                   (intron_pairs_df['int1_alt'] == \"constitutive\") &\n",
    "                                                   (intron_pairs_df['int2_alt'] == \"constitutive\")])\n",
    "    \n",
    "    neg_2const_txn_1st_spliced_2nd = len(intron_pairs_df[(intron_pairs_df['strand']==\"-\") &\n",
    "                                                        (intron_pairs_df['int1_splice'] == \"YES\") &\n",
    "                                                   (intron_pairs_df['int2_splice'] == \"NO\") &\n",
    "                                                   (intron_pairs_df['int1_alt'] == \"constitutive\") &\n",
    "                                                   (intron_pairs_df['int2_alt'] == \"constitutive\")])\n",
    "    \n",
    "    #####\n",
    "    \n",
    "    pos_2alt_txn_1st_spliced_1st = len(intron_pairs_df[(intron_pairs_df['strand']==\"+\") &\n",
    "                                                        (intron_pairs_df['int1_splice'] == \"YES\") &\n",
    "                                                   (intron_pairs_df['int2_splice'] == \"NO\") &\n",
    "                                                   (intron_pairs_df['int1_alt'] == \"alternative\") &\n",
    "                                                   (intron_pairs_df['int2_alt'] == \"alternative\")])\n",
    "    \n",
    "    neg_2alt_txn_1st_spliced_1st = len(intron_pairs_df[(intron_pairs_df['strand']==\"-\") &\n",
    "                                                        (intron_pairs_df['int1_splice'] == \"NO\") &\n",
    "                                                   (intron_pairs_df['int2_splice'] == \"YES\") &\n",
    "                                                   (intron_pairs_df['int1_alt'] == \"alternative\") &\n",
    "                                                   (intron_pairs_df['int2_alt'] == \"alternative\")])\n",
    "    \n",
    "    pos_2alt_txn_1st_spliced_2nd = len(intron_pairs_df[(intron_pairs_df['strand']==\"+\") &\n",
    "                                                        (intron_pairs_df['int1_splice'] == \"NO\") &\n",
    "                                                   (intron_pairs_df['int2_splice'] == \"YES\") &\n",
    "                                                   (intron_pairs_df['int1_alt'] == \"alternative\") &\n",
    "                                                   (intron_pairs_df['int2_alt'] == \"alternative\")])\n",
    "    \n",
    "    neg_2alt_txn_1st_spliced_2nd = len(intron_pairs_df[(intron_pairs_df['strand']==\"-\") &\n",
    "                                                        (intron_pairs_df['int1_splice'] == \"YES\") &\n",
    "                                                   (intron_pairs_df['int2_splice'] == \"NO\") &\n",
    "                                                   (intron_pairs_df['int1_alt'] == \"alternative\") &\n",
    "                                                   (intron_pairs_df['int2_alt'] == \"alternative\")])\n",
    "    \n",
    "    #####\n",
    "\n",
    "    # Calculate total for each type (pos + neg strands)   \n",
    "    const_txn_1st_spliced_1st = pos_const_txn_1st_spliced_1st + neg_const_txn_1st_spliced_1st\n",
    "    const_txn_1st_spliced_2nd = pos_const_txn_1st_spliced_2nd + neg_const_txn_1st_spliced_2nd\n",
    "    alt_txn_1st_spliced_1st = pos_alt_txn_1st_spliced_1st + neg_alt_txn_1st_spliced_1st\n",
    "    alt_txn_1st_spliced_2nd = pos_alt_txn_1st_spliced_2nd + neg_alt_txn_1st_spliced_2nd\n",
    "    two_const_txn_1st_spliced_1st = pos_2const_txn_1st_spliced_1st + neg_2const_txn_1st_spliced_1st\n",
    "    two_const_txn_1st_spliced_2nd = pos_2const_txn_1st_spliced_2nd + neg_2const_txn_1st_spliced_2nd\n",
    "    two_alt_txn_1st_spliced_1st = pos_2alt_txn_1st_spliced_1st + neg_2alt_txn_1st_spliced_1st\n",
    "    two_alt_txn_1st_spliced_2nd = pos_2alt_txn_1st_spliced_2nd + neg_2alt_txn_1st_spliced_2nd\n",
    "    \n",
    "    # Calculate total per category\n",
    "    total_const_txn_1st = const_txn_1st_spliced_1st + const_txn_1st_spliced_2nd\n",
    "    total_alt_txn_1st = alt_txn_1st_spliced_1st + alt_txn_1st_spliced_2nd\n",
    "    total_two_const_txn_1st = two_const_txn_1st_spliced_1st + two_const_txn_1st_spliced_2nd\n",
    "    total_two_alt_txn_1st = two_alt_txn_1st_spliced_1st + two_alt_txn_1st_spliced_2nd\n",
    "    \n",
    "    # Calculate total number of pairs\n",
    "    total = total_const_txn_1st + total_alt_txn_1st + total_two_const_txn_1st + total_two_alt_txn_1st\n",
    "    \n",
    "    # Calculate percentages for each of the 8 groups (although we could eventually represent only the first member\n",
    "    # of each group)\n",
    "    percent_const_txn_1st_spliced_1st = const_txn_1st_spliced_1st / total_const_txn_1st\n",
    "    percent_const_txn_1st_spliced_2nd = const_txn_1st_spliced_2nd / total_const_txn_1st\n",
    "    percent_alt_txn_1st_spliced_1st = alt_txn_1st_spliced_1st / total_alt_txn_1st\n",
    "    percent_alt_txn_1st_spliced_2nd = alt_txn_1st_spliced_2nd / total_alt_txn_1st\n",
    "    percent_two_const_txn_1st_spliced_1st = two_const_txn_1st_spliced_1st / total_two_const_txn_1st\n",
    "    percent_two_const_txn_1st_spliced_2nd = two_const_txn_1st_spliced_2nd / total_two_const_txn_1st\n",
    "    percent_two_alt_txn_1st_spliced_1st = two_alt_txn_1st_spliced_1st / total_two_alt_txn_1st\n",
    "    percent_two_alt_txn_1st_spliced_2nd = two_alt_txn_1st_spliced_2nd / total_two_alt_txn_1st\n",
    "\n",
    "    splicing_order.append([const_txn_1st_spliced_1st, const_txn_1st_spliced_2nd, alt_txn_1st_spliced_1st, alt_txn_1st_spliced_2nd,\n",
    "                          two_const_txn_1st_spliced_1st,two_const_txn_1st_spliced_2nd,two_alt_txn_1st_spliced_1st,two_alt_txn_1st_spliced_2nd])\n",
    "    \n",
    "    splicing_order_percent.append([percent_const_txn_1st_spliced_1st, percent_const_txn_1st_spliced_2nd, percent_alt_txn_1st_spliced_1st, percent_alt_txn_1st_spliced_2nd,\n",
    "                          percent_two_const_txn_1st_spliced_1st,percent_two_const_txn_1st_spliced_2nd,percent_two_alt_txn_1st_spliced_1st,percent_two_alt_txn_1st_spliced_2nd])\n",
    "\n",
    "    splicing_order_df = pd.DataFrame(splicing_order)\n",
    "    splicing_order_df.columns = ['const_txn_1st_spliced_1st', 'const_txn_1st_spliced_2nd', 'alt_txn_1st_spliced_1st', 'alt_txn_1st_spliced_2nd',\n",
    "                                'two_const_txn_1st_spliced_1st','two_const_txn_1st_spliced_2nd','two_alt_txn_1st_spliced_1st','two_alt_txn_1st_spliced_2nd']\n",
    "    splicing_order_percent_df = pd.DataFrame(splicing_order_percent)\n",
    "    splicing_order_percent_df.columns = ['const_txn_1st_spliced_1st', 'const_txn_1st_spliced_2nd', 'alt_txn_1st_spliced_1st', 'alt_txn_1st_spliced_2nd',\n",
    "                                'two_const_txn_1st_spliced_1st','two_const_txn_1st_spliced_2nd','two_alt_txn_1st_spliced_1st','two_alt_txn_1st_spliced_2nd']\n",
    "\n",
    "    return splicing_order_df,splicing_order_percent_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Human data \n",
    "\n",
    "hg38_intronFile = pd.read_table('/path/to/annotation_files/hg38_RefSeq_introns_parsed_wiAltRNAseqMISO.v2.txt')\n",
    "hg38_intronFile = hg38_intronFile[hg38_intronFile['gene'].str.startswith('NM')].reset_index()\n",
    "\n",
    "# make a dataframe of intron coordinates\n",
    "hg38_intronFile['alt_events'] = hg38_intronFile.apply(lambda row: hg38_introns_byRow(row),axis=1)\n",
    "\n",
    "# Change chromosome nomenclature\n",
    "hg38_intronFile['chrom'] = hg38_intronFile.apply(lambda row: changeChrom(row),axis=1)\n",
    "\n",
    "# Select the relevant columns and make a bedtool\n",
    "hg38_intronFile = hg38_intronFile[['chrom','start','end','gene','intron_count','strand','alternative_gtf','alt_events']]\n",
    "introns_bedtool = pybedtools.BedTool.from_dataframe(hg38_intronFile)\n",
    "\n",
    "\n",
    "# Get Drosophila alternative splicing data\n",
    "\n",
    "# upload dm6 intron file with alternative splicing\n",
    "dm6_intronFile = pd.read_table('/path/to/dm6_RefSeq_introns_parsed_wiAltRNAseqMISO.txt')\n",
    "dm6_intronFile = dm6_intronFile[dm6_intronFile['gene'].str.startswith('NM')]\n",
    "\n",
    "# make a dataframe of intron coordinates\n",
    "dm6_introns_bedtool = dmel_introns(dm6_intronFile) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload alignment files for processing (K562 cells)\n",
    "K562_1_bamFile = pybedtools.BedTool('/path/to/K562_4sUchr_ONT_1_hg38_minimap2_uniq_sort.bam')\n",
    "K562_2_bamFile = pybedtools.BedTool('/path/to/K562_4sUchr_ONT_2_hg38_minimap2_uniq_sort.bam')\n",
    "K562_3_bamFile = pybedtools.BedTool('/path/to/K562_4sUchr_ONT_3_hg38_minimap2_uniq_sort.bam')\n",
    "K562_4_bamFile = pybedtools.BedTool('/path/to/K562_4sUchr_ONT_4_hg38_minimap2_uniq_sort.bam')\n",
    "K562_5a_bamFile = pybedtools.BedTool('/path/to/K562_4sUchr_ONT_5a_hg38_minimap2_uniq_sort.bam')\n",
    "K562_5b_bamFile = pybedtools.BedTool('/path/to/K562_4sUchr_ONT_5b_hg38_minimap2_uniq_sort.bam')\n",
    "\n",
    "# upload alignment files for processing (S2 cells)\n",
    "S2_1a_bamFile = pybedtools.BedTool('/path/to/S2_4sUchr_ONT_1a_dm6_minimap2_uniq_sort.bam')\n",
    "S2_1b_bamFile = pybedtools.BedTool('/path/to/S2_4sUchr_ONT_1b_dm6_minimap2_uniq_sort.bam')\n",
    "S2_2_bamFile = pybedtools.BedTool('/path/to/S2_4sUchr_ONT_2_dm6_minimap2_uniq_sort.bam')\n",
    "S2_3_bamFile = pybedtools.BedTool('/path/to/S2_4sUchr_ONT_3_dm6_minimap2_uniq_sort.bam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get reads that intersect introns\n",
    "K562_1_intersect = get_intron_intersect(introns_bedtool, K562_1_bam_file)\n",
    "K562_2_intersect = get_intron_intersect(introns_bedtool, K562_2_bam_file)\n",
    "K562_3_intersect = get_intron_intersect(introns_bedtool, K562_3_bam_file)\n",
    "K562_4_intersect = get_intron_intersect(introns_bedtool, K562_4_bam_file)\n",
    "K562_5a_intersect = get_intron_intersect(introns_bedtool, K562_5a_bam_file)\n",
    "K562_5b_intersect = get_intron_intersect(introns_bedtool, K562_5b_bam_file)\n",
    "\n",
    "S2_1a_intersect = get_intron_intersect(dm6_introns_bedtool, S2_1a_bamFile)\n",
    "S2_1b_intersect = get_intron_intersect(dm6_introns_bedtool, S2_1b_bamFile)\n",
    "S2_2_intersect = get_intron_intersect(dm6_introns_bedtool, S2_2_bamFile)\n",
    "S2_3_intersect = get_intron_intersect(dm6_introns_bedtool, S2_3_bamFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get splicing information for every read that spans an intron\n",
    "min_overlap = 25\n",
    "\n",
    "K562_1_splice_info = get_splicing_info(K562_1_intersect,min_overlap)\n",
    "K562_2_splice_info = get_splicing_info(K562_2_intersect,min_overlap)\n",
    "K562_3_splice_info = get_splicing_info(K562_3_intersect,min_overlap)\n",
    "K562_4_splice_info = get_splicing_info(K562_4_intersect,min_overlap)\n",
    "K562_5a_splice_info = get_splicing_info(K562_5a_intersect,min_overlap)\n",
    "K562_5b_splice_info = get_splicing_info(K562_5b_intersect,min_overlap)\n",
    "\n",
    "S2_1a_splice_info = get_splicing_info(S2_1a_intersect,min_overlap)\n",
    "S2_1b_splice_info = get_splicing_info(S2_1b_intersect,min_overlap)\n",
    "S2_2_splice_info = get_splicing_info(S2_2_intersect,min_overlap)\n",
    "S2_3_splice_info = get_splicing_info(S2_3_intersect,min_overlap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rerun with only introns that overlap the read without any splicing to control for read length bias\n",
    "\n",
    "K562_1_splice_info = K562_1_splice_info[K562_1_splice_info['splice_status'] != \"UNDETERMINED\"].reset_index(drop=True)\n",
    "K562_1_splice_info_wiOverlap = K562_1_splice_info[K562_1_splice_info['read_overlap']>(K562_1_splice_info['intron_end']-K562_1_splice_info['intron_start'])].reset_index(drop=True)\n",
    "\n",
    "K562_2_splice_info = K562_2_splice_info[K562_2_splice_info['splice_status'] != \"UNDETERMINED\"].reset_index(drop=True)\n",
    "K562_2_splice_info_wiOverlap = K562_2_splice_info[K562_2_splice_info['read_overlap']>(K562_2_splice_info['intron_end']-K562_2_splice_info['intron_start'])].reset_index(drop=True)\n",
    "\n",
    "K562_3_splice_info = K562_3_splice_info[K562_3_splice_info['splice_status'] != \"UNDETERMINED\"].reset_index(drop=True)\n",
    "K562_3_splice_info_wiOverlap = K562_3_splice_info[K562_3_splice_info['read_overlap']>(K562_3_splice_info['intron_end']-K562_3_splice_info['intron_start'])].reset_index(drop=True)\n",
    "\n",
    "K562_4_splice_info = K562_4_splice_info[K562_4_splice_info['splice_status'] != \"UNDETERMINED\"].reset_index(drop=True)\n",
    "K562_4_splice_info_wiOverlap = K562_4_splice_info[K562_4_splice_info['read_overlap']>(K562_4_splice_info['intron_end']-K562_4_splice_info['intron_start'])].reset_index(drop=True)\n",
    "\n",
    "K562_5a_splice_info = K562_5a_splice_info[K562_5a_splice_info['splice_status'] != \"UNDETERMINED\"].reset_index(drop=True)\n",
    "K562_5a_splice_info_wiOverlap = K562_5a_splice_info[K562_5a_splice_info['read_overlap']>(K562_5a_splice_info['intron_end']-K562_5a_splice_info['intron_start'])].reset_index(drop=True)\n",
    "\n",
    "K562_5b_splice_info = K562_5b_splice_info[K562_5b_splice_info['splice_status'] != \"UNDETERMINED\"].reset_index(drop=True)\n",
    "K562_5b_splice_info_wiOverlap = K562_5b_splice_info[K562_5b_splice_info['read_overlap']>(K562_5b_splice_info['intron_end']-K562_5b_splice_info['intron_start'])].reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "S2_1a_splice_info = S2_1a_splice_info[S2_1a_splice_info['splice_status'] != \"UNDETERMINED\"].reset_index(drop=True)\n",
    "S2_1a_splice_info_wiOverlap = S2_1a_splice_info[S2_1a_splice_info['read_overlap']>(S2_1a_splice_info['intron_end']-S2_1a_splice_info['intron_start'])].reset_index(drop=True)\n",
    "\n",
    "S2_1b_splice_info = S2_1b_splice_info[S2_1b_splice_info['splice_status'] != \"UNDETERMINED\"].reset_index(drop=True)\n",
    "S2_1b_splice_info_wiOverlap = S2_1b_splice_info[S2_1b_splice_info['read_overlap']>(S2_1b_splice_info['intron_end']-S2_1b_splice_info['intron_start'])].reset_index(drop=True)\n",
    "\n",
    "S2_2_splice_info = S2_2_splice_info[S2_2_splice_info['splice_status'] != \"UNDETERMINED\"].reset_index(drop=True)\n",
    "S2_2_splice_info_wiOverlap = S2_2_splice_info[S2_2_splice_info['read_overlap']>(S2_2_splice_info['intron_end']-S2_2_splice_info['intron_start'])].reset_index(drop=True)\n",
    "\n",
    "S2_3_splice_info = S2_3_splice_info[S2_3_splice_info['splice_status'] != \"UNDETERMINED\"].reset_index(drop=True)\n",
    "S2_3_splice_info_wiOverlap = S2_3_splice_info[S2_3_splice_info['read_overlap']>(S2_3_splice_info['intron_end']-S2_3_splice_info['intron_start'])].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dictionary with all intron junctions that a read spans\n",
    "K562_1_splice_dictionary = get_read_junctions_dictionary(K562_1_splice_info_wiOverlap)\n",
    "K562_2_splice_dictionary = get_read_junctions_dictionary(K562_2_splice_info_wiOverlap)\n",
    "K562_3_splice_dictionary = get_read_junctions_dictionary(K562_3_splice_info_wiOverlap)\n",
    "K562_4_splice_dictionary = get_read_junctions_dictionary(K562_4_splice_info_wiOverlap)\n",
    "K562_5a_splice_dictionary = get_read_junctions_dictionary(K562_5a_splice_info_wiOverlap)\n",
    "K562_5b_splice_dictionary = get_read_junctions_dictionary(K562_5b_splice_info_wiOverlap)\n",
    "\n",
    "HL8_splice_dictionary = get_read_junctions_dictionary(HL8_splice_info_wiOverlap)\n",
    "HL9_splice_dictionary = get_read_junctions_dictionary(HL9_splice_info_wiOverlap)\n",
    "HL10_splice_dictionary = get_read_junctions_dictionary(HL10_splice_info_wiOverlap)\n",
    "HL11_splice_dictionary = get_read_junctions_dictionary(HL11_splice_info_wiOverlap)\n",
    "\n",
    "# get distribution of intron splicing across reads\n",
    "K562_1_intron_distribution = get_intron_distribution(K562_1_splice_dictionary)\n",
    "K562_2_intron_distribution = get_intron_distribution(K562_2_splice_dictionary)\n",
    "K562_3_intron_distribution = get_intron_distribution(K562_3_splice_dictionary)\n",
    "K562_4_intron_distribution = get_intron_distribution(K562_4_splice_dictionary)\n",
    "K562_5a_intron_distribution = get_intron_distribution(K562_5a_splice_dictionary)\n",
    "K562_5b_intron_distribution = get_intron_distribution(K562_5b_splice_dictionary)\n",
    "\n",
    "S2_1a_intron_distribution = get_intron_distribution(S2_1a_splice_dictionary)\n",
    "S2_1b_intron_distribution = get_intron_distribution(S2_1b_splice_dictionary)\n",
    "S2_2_intron_distribution = get_intron_distribution(S2_2_splice_dictionary)\n",
    "S2_3_intron_distribution = get_intron_distribution(S2_3_splice_dictionary)\n",
    "\n",
    "# get pie chart for intron splicing distribution\n",
    "K562_1_intron_distribution_counts = get_pie_chart_df(K562_1_intron_distribution)\n",
    "K562_2_intron_distribution_counts = get_pie_chart_df(K562_2_intron_distribution)\n",
    "K562_3_intron_distribution_counts = get_pie_chart_df(K562_3_intron_distribution)\n",
    "K562_4_intron_distribution_counts = get_pie_chart_df(K562_4_intron_distribution)\n",
    "K562_5a_intron_distribution_counts = get_pie_chart_df(K562_5a_intron_distribution)\n",
    "K562_5b_intron_distribution_counts = get_pie_chart_df(K562_5b_intron_distribution)\n",
    "\n",
    "all_hg38 = pd.concat([K562_1_intron_distribution_counts,K562_2_intron_distribution_counts,K562_3_intron_distribution_counts,\n",
    "                    K562_4_intron_distribution_counts,K562_5a_intron_distribution_counts,K562_5b_intron_distribution_counts],axis=1)\n",
    "all_hg38.columns = ['K562_1','K562_2','K562_3','K562_4','K562_5a','K562_5b']\n",
    "\n",
    "\n",
    "\n",
    "S2_1a_intron_distribution_counts = get_pie_chart_df(S2_1a_intron_distribution)\n",
    "S2_1b_intron_distribution_counts = get_pie_chart_df(S2_1b_intron_distribution)\n",
    "S2_2_intron_distribution_counts = get_pie_chart_df(S2_2_intron_distribution)\n",
    "S2_3_intron_distribution_counts = get_pie_chart_df(S2_3_intron_distribution)\n",
    "\n",
    "all_dm6 = pd.concat([S2_1a_intron_distribution_counts,S2_1b_intron_distribution_counts,S2_2_intron_distribution_counts,S2_3_intron_distribution_counts],axis=1)\n",
    "all_dm6.columns = ['S2_1a','S2_1b','S2_2','S2_3']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get information about intron pairs from read junctions dictionary\n",
    "\n",
    "alt_events = ['ALT']\n",
    "\n",
    "K562_1_intron_pairs_df = get_intron_pairs_df(K562_1_splice_dictionary, alt_events)\n",
    "K562_2_intron_pairs_df = get_intron_pairs_df(K562_2_splice_dictionary, alt_events)\n",
    "K562_3_intron_pairs_df = get_intron_pairs_df(K562_3_splice_dictionary, alt_events)\n",
    "K562_4_intron_pairs_df = get_intron_pairs_df(K562_4_splice_dictionary, alt_events)\n",
    "K562_5a_intron_pairs_df = get_intron_pairs_df(K562_5a_splice_dictionary, alt_events)\n",
    "K562_5b_intron_pairs_df = get_intron_pairs_df(K562_5b_splice_dictionary, alt_events)\n",
    "\n",
    "S2_1a_intron_pairs_df = get_intron_pairs_df(S2_1a_splice_dictionary, alt_events)\n",
    "S2_1b_intron_pairs_df = get_intron_pairs_df(S2_1b_splice_dictionary, alt_events)\n",
    "S2_2_intron_pairs_df = get_intron_pairs_df(S2_2_splice_dictionary, alt_events)\n",
    "S2_3_intron_pairs_df = get_intron_pairs_df(S2_3_splice_dictionary, alt_events)\n",
    "\n",
    "\n",
    "# save splice dataframes to file (to use again later for plotting) (K562 cells)\n",
    "K562_1_intron_pairs_df.to_csv('/path/to/K562_1_hg38_intron_pairs_df_wiAlt.txt', sep='\\t', index=False, header=True)\n",
    "K562_2_intron_pairs_df.to_csv('/path/to/K562_2_hg38_intron_pairs_df_wiAlt.txt', sep='\\t', index=False, header=True)\n",
    "K562_3_intron_pairs_df.to_csv('/path/to/K562_3_hg38_intron_pairs_df_wiAlt.txt', sep='\\t', index=False, header=True)\n",
    "K562_4_intron_pairs_df.to_csv('/path/to/K562_4_hg38_intron_pairs_df_wiAlt.txt', sep='\\t', index=False, header=True)\n",
    "K562_5a_intron_pairs_df.to_csv('/path/to/K562_5a_hg38_intron_pairs_df_wiAlt.txt', sep='\\t', index=False, header=True)\n",
    "K562_5b_intron_pairs_df.to_csv('/path/to/K562_5b_hg38_intron_pairs_df_wiAlt.txt', sep='\\t', index=False, header=True)\n",
    "\n",
    "S2_1a_intron_pairs_df.to_csv('/path/to/S2_1a_dm6_intron_pairs_df_wiAlt.txt', sep='\\t', index=False, header=True)\n",
    "S2_1b_intron_pairs_df.to_csv('/path/to/S2_1b_dm6_intron_pairs_df_wiAlt.txt', sep='\\t', index=False, header=True)\n",
    "S2_2_intron_pairs_df.to_csv('/path/to/S2_2_dm6_intron_pairs_df_wiAlt.txt', sep='\\t', index=False, header=True)\n",
    "S2_3_intron_pairs_df.to_csv('/path/to/S2_3_dm6_intron_pairs_df_wiAlt.txt', sep='\\t', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get information about intron pairs from read junctions dictionary (K562)\n",
    "K562_1_splicing_order_df = get_splicing_order_df_alt(K562_1_intron_pairs_df)[1]\n",
    "K562_2_splicing_order_df = get_splicing_order_df_alt(K562_2_intron_pairs_df)[1]\n",
    "K562_3_splicing_order_df = get_splicing_order_df_alt(K562_3_intron_pairs_df)[1]\n",
    "K562_4_splicing_order_df = get_splicing_order_df_alt(K562_4_intron_pairs_df)[1]\n",
    "K562_5a_splicing_order_df = get_splicing_order_df_alt(K562_5a_intron_pairs_df)[1]\n",
    "K562_5b_splicing_order_df = get_splicing_order_df_alt(K562_5b_intron_pairs_df)[1]\n",
    "\n",
    "# concatenate samples\n",
    "concat_splicing_order_df = pd.concat([K562_1_splicing_order_df, K562_2_splicing_order_df, K562_3_splicing_order_df,\n",
    "                                     K562_4_splicing_order_df, K562_5a_splicing_order_df, K562_5b_splicing_order_df], axis=0)\n",
    "concat_splicing_order_df.index = ['K562_1', 'K562_2', 'K562_3','K562_4','K562_5a','K562_5b']\n",
    "concat_splicing_order_df.to_csv('/path/to/K562_alt_splicing_order_df.txt', sep='\\t', index=True, header=True)\n",
    "\n",
    "# also output the counts\n",
    "K562_1_splicing_order_counts = get_splicing_order_df_alt(K562_1_intron_pairs_df)[0]\n",
    "K562_2_splicing_order_counts = get_splicing_order_df_alt(K562_2_intron_pairs_df)[0]\n",
    "K562_3_splicing_order_counts = get_splicing_order_df_alt(K562_3_intron_pairs_df)[0]\n",
    "K562_4_splicing_order_counts = get_splicing_order_df_alt(K562_4_intron_pairs_df)[0]\n",
    "K562_5a_splicing_order_counts = get_splicing_order_df_alt(K562_5a_intron_pairs_df)[0]\n",
    "K562_5b_splicing_order_counts = get_splicing_order_df_alt(K562_5b_intron_pairs_df)[0]\n",
    "\n",
    "# concatenated samples\n",
    "concat_splicing_order_counts = pd.concat([K562_1_splicing_order_counts, K562_2_splicing_order_counts,K562_3_splicing_order_counts,\n",
    "                                         K562_4_splicing_order_counts,K562_5a_splicing_order_counts,K562_5b_splicing_order_counts], axis=0)\n",
    "concat_splicing_order_counts.index = ['K562_1', 'K562_2', 'K562_3','K562_4','K562_5a','K562_5b']\n",
    "concat_splicing_order_counts.to_csv('/path/to/K562_alt_splicing_order_counts.txt', sep='\\t', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get information about intron pairs from read junctions dictionary (S2)\n",
    "S2_1_splicing_order_df = get_splicing_order_df_alt(S2_1_intron_pairs_df)[1]\n",
    "S2_1b_splicing_order_df = get_splicing_order_df_alt(S2_1b_intron_pairs_df)[1]\n",
    "S2_2_splicing_order_df = get_splicing_order_df_alt(S2_2_intron_pairs_df)[1]\n",
    "S2_3_splicing_order_df = get_splicing_order_df_alt(S2_3_intron_pairs_df)[1]\n",
    "\n",
    "# concatenate samples\n",
    "concat_splicing_order_df = pd.concat([S2_1_splicing_order_df, S2_1b_splicing_order_df, S2_2_splicing_order_df,\n",
    "                                     S2_3_splicing_order_df], axis=0)\n",
    "concat_splicing_order_df.index = ['S2_1', 'S2_1b', 'S2_2','S2_3']\n",
    "concat_splicing_order_df.to_csv('/path/to/S2_alt_splicing_order_df.txt', sep='\\t', index=True, header=True)\n",
    "\n",
    "# also output the counts\n",
    "S2_1_splicing_order_counts = get_splicing_order_df_alt(S2_1_intron_pairs_df)[0]\n",
    "S2_1b_splicing_order_counts = get_splicing_order_df_alt(S2_1b_intron_pairs_df)[0]\n",
    "S2_2_splicing_order_counts = get_splicing_order_df_alt(S2_2_intron_pairs_df)[0]\n",
    "S2_3_splicing_order_counts = get_splicing_order_df_alt(S2_3_intron_pairs_df)[0]\n",
    "\n",
    "# concatenated samples\n",
    "concat_splicing_order_counts = pd.concat([S2_1_splicing_order_counts, S2_1b_splicing_order_counts,S2_2_splicing_order_counts,\n",
    "                                         S2_3_splicing_order_counts], axis=0)\n",
    "concat_splicing_order_counts.index = ['S2_1', 'S2_1b', 'S2_2','S2_3']\n",
    "concat_splicing_order_counts.to_csv('/path/to/S2_alt_splicing_order_counts.txt', sep='\\t', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
