{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Date : August 1, 2019\n",
    "\n",
    "Author : Heather Landry Drexler\n",
    "\n",
    "This script will develop datasets for making pie charts of read\n",
    "end alignments from nano-COP data.\n",
    "\n",
    "These datasets are used for Figures 1 and 4 of the nano-COP manuscript.\n",
    "                                            \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pysam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "% matplotlib inline\n",
    "\n",
    "import math\n",
    "\n",
    "import pybedtools\n",
    "from pybedtools import BedTool\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_features_bedtool(annotation_df, polyA_window, post_polyA_window, ss_window_upstream, ss_window_downstream, RNAPET_df, RNAPET_window):\n",
    "\n",
    "    # make a set for all 3'SS coordinates\n",
    "    features = []\n",
    "\n",
    "    # loop through a file with intron coordinates\n",
    "    # check if feature is an exon\n",
    "    for i in range(0,len(annotation_df)):\n",
    "        feature = annotation_df['feature'].iloc[i].split(\"_\")[0]    # feature\n",
    " \n",
    "        if (feature == 'gene'):\n",
    "            chrom = 'chr'+annotation_df['chrom'].iloc[i]            # chromosome\n",
    "            start = int(annotation_df['start'].iloc[i])             # start coordinate of intron (last base of exon)\n",
    "            end = int(annotation_df['end'].iloc[i])                 # end coordinate of intron (last base of intron)\n",
    "            gene = annotation_df['gene'].iloc[i]                    # gene name\n",
    "            strand = annotation_df['strand'].iloc[i]                # strand of gene with intron\n",
    "            name = annotation_df['feature'].iloc[i]                 # get feature and count for output file\n",
    "   \n",
    "            if (strand=='+'):\n",
    "                polyA_start = end - polyA_window\n",
    "                polyA_end = end + polyA_window\n",
    "                post_polyA_start = end + polyA_window\n",
    "                post_polyA_end = end + polyA_window + post_polyA_window\n",
    "                \n",
    "            if (strand=='-'):\n",
    "                polyA_start = start - polyA_window\n",
    "                polyA_end = start + polyA_window\n",
    "                post_polyA_start = start - polyA_window - post_polyA_window\n",
    "                post_polyA_end = start - polyA_window\n",
    "\n",
    "            features.append([chrom,polyA_start,polyA_end,gene,'polyA',strand])\n",
    "            features.append([chrom,post_polyA_start,post_polyA_end,gene,'post_polyA',strand])\n",
    "            \n",
    "        if (feature == 'exon'):\n",
    "            chrom = 'chr'+annotation_df['chrom'].iloc[i]            # chromosome\n",
    "            start = int(annotation_df['start'].iloc[i])             # start coordinate of intron (last base of exon)\n",
    "            end = int(annotation_df['end'].iloc[i])                 # end coordinate of intron (last base of intron)\n",
    "            gene = annotation_df['gene'].iloc[i]                    # gene name\n",
    "            strand = annotation_df['strand'].iloc[i]                # strand of gene with intron\n",
    "            name = annotation_df['feature'].iloc[i]                 # get feature and count for output file\n",
    "   \n",
    "            if (end-start > 10):        \n",
    "                features.append([chrom,start,end,gene,name,strand])\n",
    "     \n",
    "        if (feature == 'intron'):\n",
    "            chrom = 'chr'+annotation_df['chrom'].iloc[i]            # chromosome\n",
    "            start = int(annotation_df['start'].iloc[i])             # start coordinate of intron (last base of exon)\n",
    "            end = int(annotation_df['end'].iloc[i])                 # end coordinate of intron (last base of intron)\n",
    "            gene = annotation_df['gene'].iloc[i]                    # gene name\n",
    "            strand = annotation_df['strand'].iloc[i]                # strand of gene with intron\n",
    "            name = annotation_df['feature'].iloc[i]                 # get feature and count for output file\n",
    "   \n",
    "            if (end-start > 10):\n",
    "                features.append([chrom,start,end,gene,name,strand])\n",
    "    \n",
    "                # get 5' splice site positions for introns on each strand\n",
    "                if (strand=='+'):\n",
    "                    ss5_start = int(start)-ss_window_upstream\n",
    "                    ss5_end = int(start)+ss_window_downstream\n",
    "                if (strand=='-'):\n",
    "                    ss5_start = int(end)-ss_window_downstream\n",
    "                    ss5_end = int(end)+ss_window_upstream\n",
    "\n",
    "                if (ss5_start > 0 and ss5_end > ss5_start):\n",
    "                    features.append([chrom,ss5_start,ss5_end,gene,name+\"_SS\",strand])\n",
    "\n",
    "\n",
    "    for i in range(0,len(RNAPET_df)):\n",
    "\n",
    "        # get features of line in RNA-PET bed file\n",
    "        chrom = RNAPET_df.iloc[i]['chrom']\n",
    "        start = RNAPET_df.iloc[i]['start']\n",
    "        end = RNAPET_df.iloc[i]['end']\n",
    "        ID = RNAPET_df.iloc[i]['ID']\n",
    "        score = RNAPET_df.iloc[i]['score'].astype(str)\n",
    "        strand = RNAPET_df.iloc[i]['strand']\n",
    "        size = RNAPET_df.iloc[i]['size'].split(',')\n",
    "        loc = RNAPET_df.iloc[i]['loc'].split(',')\n",
    "\n",
    "        # process file based on read strand\n",
    "        # make a new bed file with only information about the polyA site\n",
    "\n",
    "        if (strand == \"+\"):\n",
    "            polyA_start = end - int(size[1]) + 1 - RNAPET_window\n",
    "            polyA_end = end + RNAPET_window\n",
    "\n",
    "        if (strand == \"-\"): \n",
    "            polyA_start = start + 1 - RNAPET_window\n",
    "            polyA_end = start + int(size[0]) + RNAPET_window\n",
    "\n",
    "        if (polyA_start > 0):\n",
    "            features.append([chrom,polyA_start,polyA_end,ID,'RNAPET',strand])\n",
    "\n",
    "    features_bedtool = BedTool(features)\n",
    "    return features_bedtool\n",
    "\n",
    "\n",
    "def get_read_end_bedtool(bamFile):\n",
    "\n",
    "    bedFile = bamFile.bam_to_bed()\n",
    "    bedFile_df = bedFile.to_dataframe(low_memory=False)\n",
    "        \n",
    "    read_end = []\n",
    "        \n",
    "    for i in range(0,len(bedFile_df)):\n",
    "\n",
    "        chrom = str(bedFile_df['chrom'].iloc[i])\n",
    "        if (chrom[0:2]!='chr'):\n",
    "            chrom = 'chr'+chrom\n",
    "        start = bedFile_df['start'].iloc[i]\n",
    "        end = bedFile_df['end'].iloc[i]\n",
    "        read = bedFile_df['name'].iloc[i]\n",
    "        score = bedFile_df['score'].iloc[i]\n",
    "        strand = bedFile_df['strand'].iloc[i]\n",
    "\n",
    "        if (strand == \"-\"):\n",
    "            pos_1 = start\n",
    "            pos_2 = start + 1\n",
    "\n",
    "        if (strand == \"+\"):\n",
    "            pos_1 = end - 1\n",
    "            pos_2 = end\n",
    "\n",
    "        read_end.append([chrom,pos_1,pos_2,read,score,strand])\n",
    "\n",
    "    read_end_bedtool = BedTool(read_end)\n",
    "    return read_end_bedtool\n",
    "\n",
    "\n",
    "\n",
    "def get_intersect(read_ends, intron_info):\n",
    "\n",
    "    intersect = read_ends.intersect(intron_info, wo=True, s=True) # intersect reads from bam file with 3' splice site coordinates, ensure strandedness\n",
    "    intersect_df = intersect.to_dataframe(names=['chrom_read', 'start_read', 'end_read', 'name_read', 'qual_read', \\\n",
    "                                           'strand_read', 'chr_feature', 'start_feature', \\\n",
    "                                           'end_feature', 'name_gene', 'name_feature', 'strand_feature', 'count'], \\\n",
    "                               dtype={\"chrom_read\": str, \"start_read\": int, \"end_read\": int, \\\n",
    "                                     \"name_read\": str, \"qual_read\": int, \"strand_read\": str, \\\n",
    "                                    \"chr_feature\": str, \"start_feature\": int, \"end_feature\": int, \"name_gene\": str, \\\n",
    "                                     \"name_feature\": str,\"strand_feature\": str, \"count\": int}) # convert to a dataframe\n",
    "\n",
    "    return intersect_df\n",
    "\n",
    "\n",
    "\n",
    "def get_read_end_mapping(intersect_df):\n",
    "\n",
    "    read_ends = {}\n",
    "\n",
    "    for i in range(0,len(intersect_df)):\n",
    "\n",
    "        # get read name and feature type\n",
    "        read = intersect_df['name_read'].iloc[i]\n",
    "        feature = intersect_df['name_feature'].iloc[i]\n",
    "\n",
    "        # if 'polyA' is present in the feature (either alone or with 'post')\n",
    "        # report the feature as is\n",
    "        if ('polyA' in feature):\n",
    "            feature_type = feature\n",
    "\n",
    "        # if 'RNAPET' is present in the feature, report the feature as is\n",
    "        elif ('RNAPET' in feature):\n",
    "            feature_type = feature\n",
    "\n",
    "        # if length of splitting feature name by '_' is 2, it means that \n",
    "        # the feature is either an exon or intron and program will report it\n",
    "        elif (len(feature.split('_')) == 2):\n",
    "            feature_type = feature.split('_')[0]\n",
    "            feature_count = feature.split('_')[1]\n",
    "\n",
    "        # if length of splitting feature name by '_' is 3, it means that \n",
    "        # the feature is a splice site and program will report it\n",
    "        elif (len(feature.split('_')) == 3):\n",
    "            feature_type = 'intron_'+feature.split('_')[2]\n",
    "            feature_count = feature.split('_')[1]\n",
    "\n",
    "        # if length of splitting feature name by '_' is not 2 or 3, it means that \n",
    "        # there was an error somewhere in the pipeline\n",
    "        elif (len(feature.split('_')) != 2 or len(feature.split('_')) != 3):\n",
    "            print(\"ERROR with read: \"+str(read))\n",
    "\n",
    "        # check if read name is in the dictionary, if not save it\n",
    "        if read not in read_ends.keys():\n",
    "\n",
    "            # make a new dictionary for the read and end mapping info\n",
    "            read_ends[read] = [feature_type]\n",
    "\n",
    "        # check if read name is in the dictionary, if not save it\n",
    "        if read in read_ends.keys():\n",
    "\n",
    "            # if end mapping info is different, append it to the dictionary\n",
    "            if (feature_type not in read_ends[read]):\n",
    "                read_ends[read].append(feature_type)\n",
    "    \n",
    "    return read_ends\n",
    "\n",
    "\n",
    "def get_read_end_stats(read_ends):\n",
    "    \n",
    "    read_features = []\n",
    "\n",
    "    for k, v in read_ends.items():\n",
    "\n",
    "        if (len(v) == 1):\n",
    "            read_features.append([k,v[0]])\n",
    "\n",
    "        if (len(v) > 1):\n",
    "            if (\"polyA\" in v):\n",
    "                read_features.append([k,\"polyA\"])\n",
    "\n",
    "            elif (\"post_polyA\" in v):\n",
    "                read_features.append([k,\"post_polyA\"])\n",
    "\n",
    "            elif (\"intron_SS\" in v):\n",
    "                read_features.append([k,\"splice_site\"])\n",
    "\n",
    "            elif (\"RNAPET\" in v):\n",
    "                read_features.append([k,\"RNAPET\"])\n",
    "\n",
    "            else:\n",
    "                read_features.append([k,\"undetermined\"])\n",
    "\n",
    "    read_features_df = pd.DataFrame(read_features)\n",
    "    read_features_df.columns = ['read','end_feature']\n",
    "    \n",
    "    return read_features_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in datasets for Supplemental Figure 4A-C - read 3' end positions\n",
    "\n",
    "# read in features file\n",
    "hg38_all_features = pd.read_table('/path/to/annotation_files/hg38_all_features_polyA50_postpolyA500_ssUp50_ssDown10_RNAPET50.txt', header=None)\n",
    "hg38_all_features = BedTool(hg38_all_features.values.tolist())\n",
    "\n",
    "# read in features file\n",
    "dmel6_all_features = pd.read_table('/path/to/annotation_files/dmel6_all_features_polyA50_postpolyA500_ssUp50_ssDown10.txt', header=None)\n",
    "dmel6_all_features = BedTool(dmel6_all_features.values.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supplemental Figure 4A - K562 w/ polyA addition\n",
    "\n",
    "# upload K562 alignment file for analysis - this is the merged BAM file from all poly(A)-tailed K562 samples\n",
    "K562_bamFile = pybedtools.BedTool('/path/to/all_K562_hg38_minimap2_uniq_sort.bam')\n",
    "\n",
    "# get read ends and turn into a bedtool for intersecting \n",
    "K562_read_ends = get_read_end_bedtool(K562_bamFile)\n",
    "\n",
    "# intersect read ends with genome features\n",
    "K562_intersect = get_intersect(K562_read_ends, hg38_all_features)\n",
    "\n",
    "# get read ends dictionary\n",
    "K562_read_end_mapping = get_read_end_mapping(K562_intersect)\n",
    "\n",
    "# get read end mapping statistics\n",
    "K562_read_end_stats = get_read_end_stats(K562_read_end_mapping)\n",
    "\n",
    "\n",
    "# save to csv for plotting\n",
    "K562_read_ends_df = K562_read_ends.to_dataframe()\n",
    "K562_read_ends_df.to_csv('/path/to/K562_read_ends.txt', sep='\\t', index=False, header=True)\n",
    "K562_read_end_stats.to_csv('/path/to/K562_read_end_stats.txt', sep='\\t', index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Supplemental Figure 4B - K562 w/out polyA addition\n",
    "\n",
    "# upload K562 alignment file for analysis\n",
    "K562_no_tailing_bamFile = pybedtools.BedTool('/path/to/K562_4sUchr_ONT_no_tailing_hg38_minimap2_uniq_sort.bam')\n",
    "\n",
    "# get read ends and turn into a bedtool for intersecting \n",
    "K562_no_tailing_read_ends = get_read_end_bedtool(K562_no_tailing_bamFile)\n",
    "\n",
    "# intersect read ends with genome features\n",
    "K562_no_tailing_intersect = get_intersect(K562_no_tailing_read_ends, hg38_all_features)\n",
    "\n",
    "# get read ends dictionary\n",
    "K562_no_tailing_read_end_mapping = get_read_end_mapping(K562_no_tailing_intersect)\n",
    "\n",
    "# get read end mapping statistics\n",
    "K562_no_tailing_read_end_stats = get_read_end_stats(K562_no_tailing_read_end_mapping)\n",
    "\n",
    "# create a dataframe for plotting the read end mapping pie chart\n",
    "#K562_no_tailing_pie_chart_df = get_pie_chart_df(K562_no_tailing_read_end_stats,K562_no_tailing_read_ends)\n",
    "\n",
    "\n",
    "# save to csv for plotting\n",
    "K562_no_tailing_read_ends_df = K562_no_tailing_read_ends.to_dataframe()\n",
    "K562_no_tailing_read_ends_df.to_csv('/path/to/K562_no_tailing_read_ends.txt', sep='\\t', index=False, header=True)\n",
    "K562_no_tailing_read_end_stats.to_csv('/path/to/K562_no_tailing_read_end_stats.txt', sep='\\t', index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Supplemental Figure 4C - S2 w/out polyA addition\n",
    "\n",
    "# upload S2 alignment file for analysis - this is the merged BAM file from all S2 samples\n",
    "S2_bamFile = pybedtools.BedTool('/path/to/all_S2_180420_dmel6_minimap2_uniq_sort.bam')\n",
    "\n",
    "# get read ends and turn into a bedtool for intersecting \n",
    "S2_read_ends = get_read_end_bedtool(S2_bamFile)\n",
    "\n",
    "# intersect read ends with genome features\n",
    "S2_intersect = get_intersect(S2_read_ends, dmel6_all_features)\n",
    "\n",
    "# get read ends dictionary\n",
    "S2_read_end_mapping = get_read_end_mapping(S2_intersect)\n",
    "\n",
    "# get read end mapping statistics\n",
    "S2_read_end_stats = get_read_end_stats(S2_read_end_mapping)\n",
    "\n",
    "\n",
    "# save to csv for plotting\n",
    "S2_read_ends_df = S2_read_ends.to_dataframe()\n",
    "S2_read_ends_df.to_csv('/path/to/S2_read_ends.txt', sep='\\t', index=False, header=True)\n",
    "S2_read_end_stats.to_csv('/path/to/S2_read_end_stats.txt', sep='\\t', index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K562 promethION run w/ polyI addition\n",
    "\n",
    "# upload K562 alignment file for analysis \n",
    "K562_4_bamFile = pybedtools.BedTool('/path/to/K562_4sUchr_ONT_4_hg38_minimap2_uniq_sort.bam')\n",
    "\n",
    "# get read ends and turn into a bedtool for intersecting \n",
    "K562_4_read_ends = get_read_end_bedtool(K562_4_bamFile)\n",
    "\n",
    "# intersect read ends with genome features\n",
    "K562_4_intersect = get_intersect(K562_4_read_ends, hg38_all_features)\n",
    "\n",
    "# get read ends dictionary\n",
    "K562_4_read_end_mapping = get_read_end_mapping(K562_4_intersect)\n",
    "\n",
    "# get read end mapping statistics\n",
    "K562_4_read_end_stats = get_read_end_stats(K562_4_read_end_mapping)\n",
    "\n",
    "# save read ends datasets to file\n",
    "K562_4_read_ends_df = K562_4_read_ends.to_dataframe()\n",
    "K562_4_read_ends_df.to_csv('/path/to/K562_4_read_ends.txt', sep='\\t', index=False, header=True)\n",
    "K562_4_read_end_stats.to_csv('/path/to/K562_4_read_end_stats.txt', sep='\\t', index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K562 minION run w/ polyI addition\n",
    "\n",
    "# upload K562 alignment file for analysis\n",
    "K562_5a_bamFile = pybedtools.BedTool('/path/to/K562_4sUchr_ONT_5a_hg38_minimap2_uniq_sort.bam')\n",
    "\n",
    "# get read ends and turn into a bedtool for intersecting \n",
    "K562_5a_read_ends = get_read_end_bedtool(K562_5a_bamFile)\n",
    "\n",
    "# intersect read ends with genome features\n",
    "K562_5a_intersect = get_intersect(K562_5a_read_ends, hg38_all_features)\n",
    "\n",
    "# get read ends dictionary\n",
    "K562_5a_read_end_mapping = get_read_end_mapping(K562_5a_intersect)\n",
    "\n",
    "# get read end mapping statistics\n",
    "K562_5a_read_end_stats = get_read_end_stats(K562_5a_read_end_mapping)\n",
    "\n",
    "# save read ends datasets to file\n",
    "K562_5a_read_ends_df = K562_5a_read_ends.to_dataframe()\n",
    "K562_5a_read_ends_df.to_csv('/path/to/K562_5a_read_ends.txt', sep='\\t', index=False, header=True)\n",
    "K562_5a_read_end_stats.to_csv('/path/to/K562_5a_read_end_stats.txt', sep='\\t', index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K562 promethION run w/ polyI addition\n",
    "\n",
    "# upload K562 alignment file for analysis\n",
    "K562_5b_bamFile = pybedtools.BedTool('/path/to/K562_4sUchr_ONT_5b_hg38_minimap2_uniq_sort.bam')\n",
    "\n",
    "# get read ends and turn into a bedtool for intersecting \n",
    "K562_5b_read_ends = get_read_end_bedtool(K562_5b_bamFile)\n",
    "\n",
    "# intersect read ends with genome features\n",
    "K562_5b_intersect = get_intersect(K562_5b_read_ends, hg38_all_features)\n",
    "\n",
    "# get read ends dictionary\n",
    "K562_5b_read_end_mapping = get_read_end_mapping(K562_5b_intersect)\n",
    "\n",
    "# get read end mapping statistics\n",
    "K562_5b_read_end_stats = get_read_end_stats(K562_5b_read_end_mapping)\n",
    "\n",
    "# save read ends datasets to file\n",
    "K562_5b_read_ends_df = K562_5b_read_ends.to_dataframe()\n",
    "K562_5b_read_ends_df.to_csv('/path/to/K562_5b_read_ends.txt', sep='\\t', index=False, header=True)\n",
    "K562_5b_read_end_stats.to_csv('/path/to/K562_5b_read_end_stats.txt', sep='\\t', index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
