{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Date : August 1, 2019\n",
    "\n",
    "Author : Heather Landry Drexler\n",
    "\n",
    "This script will develop the datasets necessary for making percent spliced by \n",
    "distance transcribed plots from nano-COP data. These files serve as input for the\n",
    "scripts for Figures 2, 3 and S5.\n",
    "                                            \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "import pybedtools\n",
    "from pybedtools import BedTool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discarded_features_wiRNAPET_wiNoPolyA_bedtool(annotation_df, polyA_window, ss_window_upstream, ss_window_downstream, RNAPET_df, RNAPET_window, nopolyA_bamFile):\n",
    "\n",
    "    # make a set for all 3'SS coordinates\n",
    "    features = []\n",
    "    \n",
    "    # loop through a file with intron coordinates\n",
    "    for i in range(0,len(annotation_df)):\n",
    "        feature = annotation_df['feature'].iloc[i].split(\"_\")[0]    # feature\n",
    "         \n",
    "        # check if feature is a gene and record region around polyA site\n",
    "        if (feature == 'gene'):\n",
    "            chrom = 'chr'+str(annotation_df['chrom'].iloc[i])       # chromosome\n",
    "            start = int(annotation_df['start'].iloc[i])             # start coordinate of intron (last base of exon)\n",
    "            end = int(annotation_df['end'].iloc[i])                 # end coordinate of intron (last base of intron)\n",
    "            gene = annotation_df['gene'].iloc[i]                    # gene name\n",
    "            strand = annotation_df['strand'].iloc[i]                # strand of gene with intron\n",
    "            name = annotation_df['feature'].iloc[i]                 # get feature and count for output file\n",
    "   \n",
    "            if (strand=='+'):\n",
    "                polyA_start = end - polyA_window\n",
    "                polyA_end = end + polyA_window\n",
    "                \n",
    "            if (strand=='-'):\n",
    "                polyA_start = start - polyA_window\n",
    "                polyA_end = start + polyA_window\n",
    "\n",
    "            if (polyA_window > 0):\n",
    "                features.append([chrom,polyA_start,polyA_end,gene,'polyA',strand])\n",
    "            \n",
    "        # check if feature is an intron and record region around 5'SS site   \n",
    "        if (feature == 'intron'):\n",
    "            chrom = 'chr'+str(annotation_df['chrom'].iloc[i])       # chromosome\n",
    "            start = int(annotation_df['start'].iloc[i])             # start coordinate of intron (last base of exon)\n",
    "            end = int(annotation_df['end'].iloc[i])                 # end coordinate of intron (last base of intron)\n",
    "            gene = annotation_df['gene'].iloc[i]                    # gene name\n",
    "            strand = annotation_df['strand'].iloc[i]                # strand of gene with intron\n",
    "            name = annotation_df['feature'].iloc[i]                 # get feature and count for output file\n",
    "   \n",
    "            # get 5' splice site positions for introns on each strand\n",
    "            if (strand=='+'):\n",
    "                ss5_start = int(start)-ss_window_upstream\n",
    "                ss5_end = int(start)+ss_window_downstream\n",
    "            if (strand=='-'):\n",
    "                ss5_start = int(end)-ss_window_downstream\n",
    "                ss5_end = int(end)+ss_window_upstream\n",
    "\n",
    "            if (ss5_start > 0 and ss5_end > ss5_start):\n",
    "                features.append([chrom,ss5_start,ss5_end,gene,name+\"_SS\",strand])\n",
    "\n",
    "    # record regions around 3' end RNA-PET coordinates from ENCODE data\n",
    "    for i in range(0,len(RNAPET_df)):\n",
    "\n",
    "        # get features of line in RNA-PET bed file\n",
    "        chrom = str(RNAPET_df.iloc[i]['chrom'])\n",
    "        start = RNAPET_df.iloc[i]['start']\n",
    "        end = RNAPET_df.iloc[i]['end']\n",
    "        ID = RNAPET_df.iloc[i]['ID']\n",
    "        score = RNAPET_df.iloc[i]['score'].astype(str)\n",
    "        strand = RNAPET_df.iloc[i]['strand']\n",
    "        size = RNAPET_df.iloc[i]['size'].split(',')\n",
    "        loc = RNAPET_df.iloc[i]['loc'].split(',')\n",
    "\n",
    "        # process file based on read strand\n",
    "        # make a new bed file with only information about the polyA site\n",
    "\n",
    "        if (strand == \"+\"):\n",
    "            polyA_start = end - int(size[1]) + 1 - RNAPET_window\n",
    "            polyA_end = end + RNAPET_window\n",
    "\n",
    "        if (strand == \"-\"): \n",
    "            polyA_start = start + 1 - RNAPET_window\n",
    "            polyA_end = start + int(size[0]) + RNAPET_window\n",
    "\n",
    "        if (polyA_start > 0):\n",
    "            features.append([chrom,polyA_start,polyA_end,ID,'polyA',strand])\n",
    "        \n",
    "    nopolyA_df = nopolyA_bamFile.bam_to_bed().to_dataframe()\n",
    "    for i in range(len(nopolyA_df)):\n",
    "\n",
    "        chrom = \"chr\"+str(nopolyA_df.iloc[i]['chrom'])\n",
    "        read_start = nopolyA_df.iloc[i]['start']\n",
    "        read_end = nopolyA_df.iloc[i]['end']\n",
    "        read_name = nopolyA_df.iloc[i]['name']\n",
    "        strand = nopolyA_df.iloc[i]['strand']\n",
    "    \n",
    "        if strand==\"+\":\n",
    "\n",
    "            polyA_start = int(read_end)-50\n",
    "            polyA_end = int(read_end)+50\n",
    "\n",
    "        if strand==\"-\":\n",
    "\n",
    "            polyA_start = int(read_start)-50\n",
    "            polyA_end = int(read_start)+50\n",
    "\n",
    "        if (polyA_start > 0):\n",
    "            features.append([chrom,polyA_start,polyA_end,read_name,'polyA',strand])    \n",
    "\n",
    "    features_bedtool = BedTool(features)\n",
    "    return features_bedtool\n",
    "\n",
    "\n",
    "def get_discarded_features_woRNAPET_bedtool(annotation_df, polyA_window, ss_window_upstream, ss_window_downstream):\n",
    "\n",
    "    # make a set for all 3'SS coordinates\n",
    "    features = []\n",
    "\n",
    "    # loop through a file with intron coordinates\n",
    "    # check if feature is an exon\n",
    "    for i in range(0,len(annotation_df)):\n",
    "        feature = annotation_df['feature'].iloc[i].split(\"_\")[0]    # feature\n",
    " \n",
    "        if (feature == 'gene'):\n",
    "            chrom = 'chr'+str(annotation_df['chrom'].iloc[i])       # chromosome\n",
    "            start = int(annotation_df['start'].iloc[i])             # start coordinate of intron (last base of exon)\n",
    "            end = int(annotation_df['end'].iloc[i])                 # end coordinate of intron (last base of intron)\n",
    "            gene = annotation_df['gene'].iloc[i]                    # gene name\n",
    "            strand = annotation_df['strand'].iloc[i]                # strand of gene with intron\n",
    "            name = annotation_df['feature'].iloc[i]                 # get feature and count for output file\n",
    "   \n",
    "            if (strand=='+'):\n",
    "                polyA_start = end - polyA_window\n",
    "                polyA_end = end + polyA_window\n",
    "                \n",
    "            if (strand=='-'):\n",
    "                polyA_start = start - polyA_window\n",
    "                polyA_end = start + polyA_window\n",
    "\n",
    "            if (polyA_window > 0):\n",
    "                features.append([chrom,polyA_start,polyA_end,gene,'polyA',strand])\n",
    "            \n",
    "   \n",
    "        if (feature == 'intron'):\n",
    "            chrom = 'chr'+str(annotation_df['chrom'].iloc[i])       # chromosome\n",
    "            start = int(annotation_df['start'].iloc[i])             # start coordinate of intron (last base of exon)\n",
    "            end = int(annotation_df['end'].iloc[i])                 # end coordinate of intron (last base of intron)\n",
    "            gene = annotation_df['gene'].iloc[i]                    # gene name\n",
    "            strand = annotation_df['strand'].iloc[i]                # strand of gene with intron\n",
    "            name = annotation_df['feature'].iloc[i]                 # get feature and count for output file\n",
    "   \n",
    "            # get 5' splice site positions for introns on each strand\n",
    "            if (strand=='+'):\n",
    "                ss5_start = int(start)-ss_window_upstream\n",
    "                ss5_end = int(start)+ss_window_downstream\n",
    "            if (strand=='-'):\n",
    "                ss5_start = int(end)-ss_window_downstream\n",
    "                ss5_end = int(end)+ss_window_upstream\n",
    "\n",
    "            if (ss5_start > 0 and ss5_end > ss5_start):\n",
    "                features.append([chrom,ss5_start,ss5_end,gene,name+\"_SS\",strand])\n",
    "\n",
    "    features_bedtool = BedTool(features)\n",
    "    return features_bedtool\n",
    "\n",
    "\n",
    "# make a bed tool with coordinates of read 3' ends\n",
    "def get_read_end_bedtool(bamFile):\n",
    "\n",
    "    bedFile = bamFile.bam_to_bed()\n",
    "    bedFile_df = bedFile.to_dataframe(names=['chrom', 'start', 'end', 'name', 'score', 'strand'], \\\n",
    "                               dtype={\"chrom\": str, \"start\": int, \"end\": int, \"name\": str, \\\n",
    "                                      \"score\": int, \"strand\": str}) # convert to a dataframe       \n",
    "    read_end = []\n",
    "        \n",
    "    for i in range(0,len(bedFile_df)):\n",
    "\n",
    "        chrom = 'chr'+str(bedFile_df['chrom'].iloc[i])\n",
    "        start = bedFile_df['start'].iloc[i]\n",
    "        end = bedFile_df['end'].iloc[i]\n",
    "        read = bedFile_df['name'].iloc[i]\n",
    "        score = bedFile_df['score'].iloc[i]\n",
    "        strand = bedFile_df['strand'].iloc[i]\n",
    "\n",
    "        if (strand == \"-\"):\n",
    "            pos_1 = start\n",
    "            pos_2 = start + 1\n",
    "\n",
    "        if (strand == \"+\"):\n",
    "            pos_1 = end - 1\n",
    "            pos_2 = end\n",
    "\n",
    "        read_end.append([chrom,pos_1,pos_2,read,score,strand])\n",
    "\n",
    "    read_end_bedtool = BedTool(read_end)\n",
    "    return read_end_bedtool\n",
    "\n",
    "\n",
    "# intersect 3' ends with discarded features bed file \n",
    "# to get reads that will be removed from the analysis\n",
    "def get_discarded_reads(bamFile, features):\n",
    "\n",
    "    # get read ends and turn into a bedtool for intersecting \n",
    "    read_ends_bedtool = get_read_end_bedtool(bamFile)\n",
    "\n",
    "    # intersect read ends with genome features\n",
    "    intersect = read_ends_bedtool.intersect(features, wo=True, s=True) # intersect reads from bam file with 3' splice site coordinates, ensure strandedness\n",
    "    intersect_df = intersect.to_dataframe(names=['chrom_read', 'start_read', 'end_read', 'name_read', 'qual_read', \\\n",
    "                                           'strand_read', 'chr_feature', 'start_feature', \\\n",
    "                                           'end_feature', 'name_gene', 'name_feature', 'strand_feature', 'count'], \\\n",
    "                               dtype={\"chrom_read\": str, \"start_read\": int, \"end_read\": int, \\\n",
    "                                     \"name_read\": str, \"qual_read\": int, \"strand_read\": str, \\\n",
    "                                    \"chr_feature\": str, \"start_feature\": int, \"end_feature\": int, \"name_gene\": str, \\\n",
    "                                     \"name_feature\": str,\"strand_feature\": str, \"count\": int}) # convert to a dataframe\n",
    "\n",
    "    unique_read_names = set(intersect_df['name_read'])\n",
    "\n",
    "    return unique_read_names\n",
    "\n",
    "\n",
    "# make a bed tool with intron coordinates\n",
    "def get_introns_bedtool(annotation_df, window):\n",
    "\n",
    "    # make a set for all 3'SS coordinates\n",
    "    introns = []\n",
    "\n",
    "    # loop through a file with intron coordinates\n",
    "    # check if feature is an exon\n",
    "    for i in range(0,len(annotation_df)):\n",
    "        feature = annotation_df['feature'].iloc[i].split(\"_\")[0]    # feature\n",
    " \n",
    "        if (feature == 'intron'):\n",
    "            chrom = annotation_df['chrom'].iloc[i]                  # chromosome\n",
    "            start = int(annotation_df['start'].iloc[i])             # start coordinate of intron (last base of exon)\n",
    "            end = int(annotation_df['end'].iloc[i])                 # end coordinate of intron (last base of intron)\n",
    "            gene = annotation_df['gene'].iloc[i]                    # gene name\n",
    "            strand = annotation_df['strand'].iloc[i]                # strand of gene with intron\n",
    "            name = annotation_df['feature'].iloc[i]                 # get feature and count for output file\n",
    "   \n",
    "            if (end-start > 2*window):\n",
    "                start = start + window\n",
    "                end = end - window \n",
    "\n",
    "            introns.append([chrom,start,end,gene,name,strand])\n",
    "    \n",
    "    introns_bedtool = BedTool(introns)\n",
    "    return introns_bedtool\n",
    "\n",
    "# function to get a bedtool file with splice site info from hg38 intron coordinate bed file\n",
    "def human_spliceSites(intronFile):\n",
    "    # make a set for all 3'SS coordinates\n",
    "    introns = []\n",
    "\n",
    "    # loop through a file with intron coordinates\n",
    "    # record features about the introns\n",
    "    for line in intronFile:\n",
    "        chrom = str(line.split('\\t')[0])      # chromosome\n",
    "        start = line.split('\\t')[1]                 # start coordinate of intron (last base of exon)\n",
    "        end = line.split('\\t')[2]                   # end coordinate of intron (last base of intron)\n",
    "        name = line.split('\\t')[3]                  # gene name and polyA site for that gene (multiples are split with \"_\")\n",
    "        strand = line.split('\\t')[4][0]             # strand of gene with intron\n",
    "\n",
    "        # get 3' SS positions for introns plus one base\n",
    "        if strand=='+':\n",
    "            pos1 = int(end)\n",
    "            pos2 = int(end)+1\n",
    "            pos5prime = int(start)+1\n",
    "        if strand=='-':\n",
    "            pos1 = int(start)\n",
    "            pos2 = int(start)+1\n",
    "            pos5prime = int(end)\n",
    "\n",
    "        # make a key that will represent intron coordinates\n",
    "        introns.append([str(chrom),str(pos1),str(pos2),str(name),str(pos5prime),str(strand)])\n",
    "\n",
    "    spliceSites = BedTool(introns)\n",
    "    intronFile.close()\n",
    "    return spliceSites\n",
    "\n",
    "\n",
    "# function to get a bedtool file with splice site info from dm6 intron coordinate bed file\n",
    "def drosophila_spliceSites(intronFile):\n",
    "    # make a set for all 3'SS coordinates\n",
    "    introns = []\n",
    "\n",
    "    # loop through a file with intron coordinates\n",
    "    # record features about the introns\n",
    "    for line in intronFile:\n",
    "        chrom = 'chr'+str(line.split('\\t')[0])      # chromosome\n",
    "        start = line.split('\\t')[1]                 # start coordinate of intron (last base of exon)\n",
    "        end = line.split('\\t')[2]                   # end coordinate of intron (last base of intron)\n",
    "        name = line.split('\\t')[3]                  # gene name and polyA site for that gene (multiples are split with \"_\")\n",
    "        strand = line.split('\\t')[4][0]             # strand of gene with intron\n",
    "\n",
    "        # get 3' SS positions for introns plus one base\n",
    "        if strand=='+':\n",
    "            pos1 = int(end)\n",
    "            pos2 = int(end)+1\n",
    "            pos5prime = int(start)+1\n",
    "        if strand=='-':\n",
    "            pos1 = int(start)\n",
    "            pos2 = int(start)+1\n",
    "            pos5prime = int(end)\n",
    "\n",
    "        # make a key that will represent intron coordinates\n",
    "        introns.append([str(chrom),str(pos1),str(pos2),str(name),str(pos5prime),str(strand)])\n",
    "\n",
    "    spliceSites = BedTool(introns)\n",
    "    intronFile.close()\n",
    "    return spliceSites\n",
    "\n",
    "\n",
    "# function to create a dataframe with reads that span 3'SS positions\n",
    "def get_spliceSite_df(spliceSites, bamFile):\n",
    "    # get reads that span 3' splice sites and convert to a dataframe\n",
    "    bedFile = bamFile.bam_to_bed(cigar=True, tag='NM') # convert bam file to bed file, keep cigar string and NM (edit distance) tag\n",
    "    intersect = bedFile.intersect(spliceSites, wo=True, s=True) # intersect reads from bam file with 3' splice site coordinates, ensure strandedness\n",
    "    df = intersect.to_dataframe(names=['chrom', 'start_aln', 'end_aln', 'name_aln', 'qual_aln', \\\n",
    "                                           'strand_aln', 'cigar_aln', 'chr_3SS', 'start_3SS', \\\n",
    "                                           'end_3SS', 'name_gene_polyA', 'pos_5SS', 'strand_gene', 'count'], \\\n",
    "                               dtype={\"chrom\": str, \"start_aln\": int, \"end_aln\": int, \\\n",
    "                                     \"name_aln\": str, \"qual_aln\": int, \"strand_aln\": str, \\\n",
    "                                     \"cigar_aln\": str, \"chr_3SS\": str, \"start_3SS\": int, \\\n",
    "                                     \"end_3SS\": int, \"name_gene_polyA\": str, \\\n",
    "                                     \"pos_5SS\": int,\"strand_gene\": str, \"count\": int}) # convert to a dataframe\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_MinION_spliceCalls(df, min_overlap):\n",
    "    \n",
    "    # prepare a list for splice calls\n",
    "    spliceCalls = []\n",
    "\n",
    "    # set variables for parsing the cigar string\n",
    "    pattern = re.compile('([MIDNSHPX=])')\n",
    "    Consumes_Query = [\"M\", \"I\", \"S\", \"=\", \"X\"]\n",
    "    Consumes_Reference = [\"M\", \"D\", \"N\", \"=\", \"X\"]    \n",
    "\n",
    "    # loop through all reads that span splice sites\n",
    "    for i in range(0,df.shape[0]):\n",
    "        if df.strand_gene[i] == \"-\":\n",
    "            align_3p_end = df.start_aln[i] # record 3' end of read for - strand genes\n",
    "            align_5p_end = df.end_aln[i] # record 5' end of read for - strand genes\n",
    "            pos_3SS = df.end_3SS[i] # record 3'SS position for - strand genes\n",
    "            pos_5SS = df.pos_5SS[i] # record 5'SS position for - strand genes\n",
    "            intron_start = pos_3SS # get position for the start of intron coordinate on negative strand\n",
    "            intron_end = pos_5SS # get position for the end of intron coordinate on negative strand\n",
    "\n",
    "        if df.strand_gene[i] == \"+\":\n",
    "            align_3p_end = df.end_aln[i] # record 3' end of read for + strand genes\n",
    "            align_5p_end = df.start_aln[i] # record 5' end of read for + strand genes\n",
    "            pos_3SS = df.start_3SS[i] # record 3'SS position for + strand genes \n",
    "            pos_5SS = df.pos_5SS[i] # record 5'SS position for - strand genes \n",
    "            intron_start = pos_5SS # get position for the start of intron coordinate on positive strand\n",
    "            intron_end = pos_3SS # get position for the end of intron coordinate on positive strand\n",
    "            \n",
    "        # calculate distance between 3'SS and 3'end of read \n",
    "        dist = abs(align_3p_end - pos_3SS) #*** double check this!!!\n",
    "\n",
    "        # parse cigar string into a list of tuples for easy parsing\n",
    "        Sep_Values = pattern.split(df.cigar_aln[i])[:-1]\n",
    "        CigarPairs = list((Sep_Values[n:n+2] for n in range(0, len(Sep_Values), 2)))  \n",
    "\n",
    "        # get the 3' softclip length\n",
    "        if df.strand_aln[i]==\"+\":        \n",
    "            last=len(CigarPairs)\n",
    "            if(CigarPairs[last-1][1]=='S'):\n",
    "                clip=CigarPairs[last-1][0]\n",
    "            elif(CigarPairs[last-1][1]=='H'):\n",
    "                clip=CigarPairs[last-1][0]\n",
    "            elif(CigarPairs[last-1][1]!='S' or CigarPairs[last-1][1]!='H'):\n",
    "                clip=0\n",
    "\n",
    "        if df.strand_aln[i]==\"-\":\n",
    "            if(CigarPairs[0][1]=='S'):\n",
    "                clip=CigarPairs[0][0]\n",
    "            elif(CigarPairs[0][1]=='H'):\n",
    "                clip=CigarPairs[0][0]\n",
    "            elif(CigarPairs[0][1]!='S' or CigarPairs[0][1]!='H'):\n",
    "                clip=0\n",
    "\n",
    "        # set up variables for measuring the length of cigar string operators\n",
    "        CigarOp_counts = {'M': 0, 'I': 0, 'D': 0, 'N': 0, 'S': 0, 'H': 0, 'P': 0, '=': 0, 'X': 0}\n",
    "        start_counts = {'M': 0, 'I': 0, 'D': 0, 'N': 0, 'S': 0, 'H': 0, 'P': 0, '=': 0, 'X': 0}\n",
    "        end_counts = {'M': 0, 'I': 0, 'D': 0, 'N': 0, 'S': 0, 'H': 0, 'P': 0, '=': 0, 'X': 0}\n",
    "        intron_counts = {'M': 0, 'I': 0, 'D': 0, 'N': 0, 'S': 0, 'H': 0, 'P': 0, '=': 0, 'X': 0}\n",
    "        currentloc = int(df.start_aln[i]) \n",
    "\n",
    "        # go through list of cigar strings and grab splicing information\n",
    "        for cigar_Entry in CigarPairs:\n",
    "\n",
    "            op_Length = int(cigar_Entry[0]) # get length of cigar operator\n",
    "            cigarOp = cigar_Entry[1] # get type of cigar operator  \n",
    "            CigarOp_counts[cigarOp] += op_Length # add the cigar operator length to the counts dictionary\n",
    "            cigarOp_start=currentloc # get the starting coordinate of the cigar operator\n",
    "\n",
    "            if (cigarOp in Consumes_Reference):\n",
    "                currentloc=currentloc+op_Length # add the cigar operator length to the current location coordinate \n",
    "\n",
    "            cigarOp_end=currentloc # get the ending coordinate of the cigar operator\n",
    "\n",
    "            # gather information if the portion of the cigar string spans the designated 5' splice site\n",
    "            if (cigarOp_start<intron_start-min_overlap and cigarOp_end>=intron_start-min_overlap):\n",
    "                if (cigarOp_end>=intron_start+min_overlap):\n",
    "                    count=min_overlap*2\n",
    "                else:\n",
    "                    count=cigarOp_end-(intron_start-min_overlap)+1\n",
    "                start_counts[cigarOp] += count # add the cigar operator length to the counts dictionary\n",
    "\n",
    "            elif (cigarOp_start>=intron_start-min_overlap and cigarOp_end<intron_start+min_overlap):\n",
    "                count=op_Length\n",
    "                start_counts[cigarOp] += count # add the cigar operator length to the counts dictionary       \n",
    "\n",
    "            elif (cigarOp_start<intron_start+min_overlap and cigarOp_end>=intron_start+min_overlap):\n",
    "                if (cigarOp_start<=intron_start-min_overlap):\n",
    "                    count=min_overlap*2\n",
    "                else:\n",
    "                    count=(intron_start+min_overlap)-cigarOp_start-1\n",
    "                start_counts[cigarOp] += count # add the cigar operator length to the counts dictionary \n",
    "\n",
    "            # gather information if the portion of the cigar string is within the intron\n",
    "            if (cigarOp_start<intron_start and cigarOp_end>=intron_start):\n",
    "                if (cigarOp_end>=intron_end):\n",
    "                    count=intron_end-intron_start\n",
    "                else:\n",
    "                    count=cigarOp_end-intron_start\n",
    "                intron_counts[cigarOp] += count # add the cigar operator length to the counts dictionary\n",
    "\n",
    "            elif (cigarOp_start>=intron_start and cigarOp_end<intron_end):\n",
    "                count=op_Length\n",
    "                intron_counts[cigarOp] += count # add the cigar operator length to the counts dictionary\n",
    "\n",
    "            elif (cigarOp_start<intron_end and cigarOp_end>=intron_end):\n",
    "                if (cigarOp_start<=intron_start):\n",
    "                    count=intron_end-intron_start\n",
    "                else:\n",
    "                    count=intron_end-cigarOp_start\n",
    "                intron_counts[cigarOp] += count # add the cigar operator length to the counts dictionary \n",
    "\n",
    "            # gather information if the portion of the cigar string spans the designated 3' splice site\n",
    "            if (cigarOp_start<intron_end-min_overlap and cigarOp_end>=intron_end-min_overlap):\n",
    "                if (cigarOp_end>=intron_end+min_overlap):\n",
    "                    count=min_overlap*2\n",
    "                else:\n",
    "                    count=cigarOp_end-(intron_end-min_overlap)\n",
    "                end_counts[cigarOp] += count # add the cigar operator length to the counts dictionary\n",
    "\n",
    "            elif (cigarOp_start>=intron_end-min_overlap and cigarOp_end<intron_end+min_overlap):\n",
    "                count=op_Length\n",
    "                end_counts[cigarOp] += count # add the cigar operator length to the counts dictionary\n",
    "\n",
    "            elif (cigarOp_start<intron_end+min_overlap and cigarOp_end>=intron_end+min_overlap):\n",
    "                if (cigarOp_start<=intron_end-min_overlap):\n",
    "                    count=min_overlap*2\n",
    "                else:\n",
    "                    count=(intron_end+min_overlap)-cigarOp_start\n",
    "                end_counts[cigarOp] += count # add the cigar operator length to the counts dictionary \n",
    "\n",
    "        # assign strandedness to determine counts around 5'SS and 3'SS\n",
    "        if(df.strand_gene[i]=='+'):\n",
    "            around5SS_counts = start_counts\n",
    "            around3SS_counts = end_counts\n",
    "\n",
    "        elif(df.strand_gene[i]==\"-\"):\n",
    "            around5SS_counts = end_counts\n",
    "            around3SS_counts = start_counts\n",
    "\n",
    "        # annotate splicing status based on CIGAR string information around splice sites\n",
    "        if(around3SS_counts['N']==0 and around3SS_counts['M']>min_overlap/2):\n",
    "            splice='NO'\n",
    "        elif(around3SS_counts['N']>0 and around3SS_counts['N']<min_overlap*2):\n",
    "            if(around5SS_counts['N']>0 and around5SS_counts['N']<min_overlap*2):\n",
    "                splice='YES'\n",
    "            else:\n",
    "                splice='UNDETERMINED'\n",
    "        else:\n",
    "            splice='UNDETERMINED'\n",
    "\n",
    "        # annotate splicing status based on CIGAR string information within the intron \n",
    "        if (splice == 'YES'):\n",
    "            if (float(intron_end-intron_start) > 0.0):\n",
    "                ratio = float(intron_counts['N'])/float(intron_end-intron_start)\n",
    "                difference = abs(intron_counts['N']-(intron_end-intron_start))\n",
    "                # if read is spliced, between 90-100% of the intron has to be spliced \n",
    "                # and no more than 100 nucleotides within the intron can be matching the intron sequence\n",
    "                if( ratio < 0.9 or ratio > 1.1 or difference > 100):\n",
    "                    splice='UNDETERMINED'\n",
    "            if (float(intron_end-intron_start) == 0.0):\n",
    "                splice='UNDETERMINED'\n",
    "\n",
    "        if (splice == 'NO'):\n",
    "            if (float(intron_end-intron_start) > 0.0):\n",
    "                intronLength = intron_end-intron_start\n",
    "                difference = abs(intron_counts['M']+intron_counts['D']+intron_counts['S']-intronLength)\n",
    "                ratio = float(intron_counts['M'])/(float(intron_counts['M'])+float(intron_counts['N'])+float(intron_counts['D'])+1)\n",
    "                # if read is unspliced, at least 70% of the read has to match (CIGAR=M) the intron sequence\n",
    "                # and at least 10 nucleotides must match (CIGAR=M) within the intron sequence\n",
    "                if(intron_counts['M'] < 10 or ratio < 0.7):\n",
    "                    splice='UNDETERMINED'\n",
    "            if (float(intron_end-intron_start) == 0.0):\n",
    "                splice='UNDETERMINED'\n",
    "        \n",
    "        \n",
    "        # get information on match percentage / error length \n",
    "        # this will be used as a quality control cutoff if necessary\n",
    "        read_length = CigarOp_counts['M']+CigarOp_counts['I']\n",
    "        error_rate = float(df.qual_aln[i])/float(read_length)\n",
    "\n",
    "        spliceCalls.append([df.name_aln[i],df.chrom[i],str(intron_start),str(intron_end),str(align_5p_end),str(align_3p_end),str(read_length),df.strand_gene[i],str(error_rate),str(clip),str(dist),splice,df.name_gene_polyA[i]])\n",
    "    \n",
    "    spliceCalls_df = pd.DataFrame(spliceCalls)\n",
    "    spliceCalls_df.columns = [\"read_name\",\"chrom\",\"intron_start\",\"intron_end\",\"read_start\",\"read_end\",\"read_length\",\"strand\",\"error_rate\",\"end_clippling\",\"dist_from_3SS\",\"splice_status\",\"gene_name_polyA\"]\n",
    "   \n",
    "    return spliceCalls_df\n",
    "\n",
    "\n",
    "def get_MinION_spliceCalls_noPolyA(gene_name_polyA, strand, read_end, polyA_dist):\n",
    "\n",
    "    # delimeter to identify if read has a 3' end near a polyA site\n",
    "    near_polyA = 'NO'\n",
    "\n",
    "    # count the number of polyA sites associated with a gene\n",
    "    polyA_count = len(gene_name_polyA.split('_'))/3\n",
    "\n",
    "    # loop through all polyA sites associated with the aligned gene\n",
    "    for j in range(0,polyA_count):\n",
    "        tag = gene_name_polyA.split('_')[j*3+0]\n",
    "        gene = gene_name_polyA.split('_')[j*3+1]\n",
    "        polyA = int(gene_name_polyA.split('_')[j*3+2])\n",
    "\n",
    "        if (strand=='+' and int(read_end)>(polyA-polyA_dist)):\n",
    "            near_polyA = 'YES'\n",
    "        elif (strand=='-' and int(read_end)<(polyA+polyA_dist)):\n",
    "            near_polyA = 'YES'   \n",
    "    \n",
    "    return near_polyA\n",
    "\n",
    "\n",
    "def get_processed_splice_calls(df, read_overhang, max_softclip):\n",
    "    \n",
    "    df['near_polyA'] = df.apply(lambda row: get_MinION_spliceCalls_noPolyA(row.gene_name_polyA,row.strand,row.read_end,polyA_dist), axis=1)\n",
    "    df_nopolyA = df[df['near_polyA']=='NO'].reset_index(drop=True)   \n",
    "    df_capable = df_nopolyA[(df_nopolyA['read_length'].astype(int)-read_overhang)>df_nopolyA['dist_from_3SS'].astype(int)].reset_index(drop=True)\n",
    "    df_softclip = df_capable[df_capable['end_clippling'].astype(int)<max_softclip].reset_index(drop=True)   \n",
    "    \n",
    "    return df_softclip\n",
    "\n",
    "\n",
    "def get_splice_df(bamFile, spliceSites, min_overlap, read_overhang, max_softclip):\n",
    "    \n",
    "    # get reads that span 3' splice sites and convert to a dataframe\n",
    "    bedFile = bamFile.bam_to_bed(cigar=True, tag='NM') # convert bam file to bed file, keep cigar string and NM (edit distance) tag\n",
    "\n",
    "    intersect = bedFile.intersect(spliceSites, wo=True, s=True) # intersect reads from bam file with 3' splice site coordinates, ensure strandedness\n",
    "    splicingReads = intersect.to_dataframe(names=['chrom', 'start_aln', 'end_aln', 'name_aln', 'qual_aln', \\\n",
    "                                           'strand_aln', 'cigar_aln', 'chr_3SS', 'start_3SS', \\\n",
    "                                           'end_3SS', 'name_gene_polyA', 'pos_5SS', 'strand_gene', 'count'], \\\n",
    "                               dtype={\"chrom\": str, \"start_aln\": int, \"end_aln\": int, \\\n",
    "                                     \"name_aln\": str, \"qual_aln\": int, \"strand_aln\": str, \\\n",
    "                                     \"cigar_aln\": str, \"chr_3SS\": str, \"start_3SS\": int, \\\n",
    "                                     \"end_3SS\": int, \"name_gene_polyA\": str, \\\n",
    "                                     \"pos_5SS\": int,\"strand_gene\": str, \"count\": int}) # convert to a dataframe\n",
    "    \n",
    "    splicingCalls = get_MinION_spliceCalls(splicingReads, min_overlap) #determine splicing status and distance\n",
    "    splice_df = get_processed_splice_calls(splicingCalls, read_overhang, max_softclip) #process files (e.g. not near polyA, splicing capable, and minimal softclip)\n",
    "\n",
    "    return splice_df\n",
    "\n",
    "\n",
    "def get_discarded_splice_df(bamFile, discarded_reads, spliceSites, min_overlap, read_overhang, max_softclip):\n",
    "    \n",
    "    # get reads that span 3' splice sites and convert to a dataframe\n",
    "    bedFile = bamFile.bam_to_bed(cigar=True, tag='NM') # convert bam file to bed file, keep cigar string and NM (edit distance) tag\n",
    "    filtered_reads_bedtool = bedFile.filter(lambda b: b.name not in discarded_reads)\n",
    "    filtered_reads_bedtool = filtered_reads_bedtool.saveas()\n",
    "\n",
    "    intersect = filtered_reads_bedtool.intersect(spliceSites, wo=True, s=True) # intersect reads from bam file with 3' splice site coordinates, ensure strandedness\n",
    "    splicingReads = intersect.to_dataframe(names=['chrom', 'start_aln', 'end_aln', 'name_aln', 'qual_aln', \\\n",
    "                                           'strand_aln', 'cigar_aln', 'chr_3SS', 'start_3SS', \\\n",
    "                                           'end_3SS', 'name_gene_polyA', 'pos_5SS', 'strand_gene', 'count'], \\\n",
    "                               dtype={\"chrom\": str, \"start_aln\": int, \"end_aln\": int, \\\n",
    "                                     \"name_aln\": str, \"qual_aln\": int, \"strand_aln\": str, \\\n",
    "                                     \"cigar_aln\": str, \"chr_3SS\": str, \"start_3SS\": int, \\\n",
    "                                     \"end_3SS\": int, \"name_gene_polyA\": str, \\\n",
    "                                     \"pos_5SS\": int,\"strand_gene\": str, \"count\": int}) # convert to a dataframe\n",
    "    \n",
    "    splicingCalls = get_MinION_spliceCalls(splicingReads, min_overlap) #determine splicing status and distance\n",
    "    splice_df = get_processed_splice_calls(splicingCalls, read_overhang, max_softclip) #process files (e.g. not near polyA, splicing capable, and minimal softclip)\n",
    "\n",
    "    return splice_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set all variables for analysis\n",
    "# set variables for analysis\n",
    "\n",
    "# discarded reads\n",
    "polyA_window = 50           # set window for polyA measurement from gtf file\n",
    "ss_window_upstream = 50      # set window for splice sites measurement from gtf file (upstream of 5'SS)\n",
    "ss_window_downstream = 10    # set window for splice sites measurement from gtf file (downstream of 5'SS)\n",
    "RNAPET_window = 50          # set window for transcript ends from RNA-PET data\n",
    "\n",
    "# splicing dataframe\n",
    "min_overlap = 25    # overlap required to call splicing\n",
    "\n",
    "# splicing dataframe\n",
    "polyA_dist = 150    # distance from polyA site to designate 3' end within gene\n",
    "read_overhang = 150    # distance that read has to overlap upstream of 3' SS\n",
    "max_softclip = 150    # maximum softclipping allowed at the start of the read\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload files for processing (K562 cells)\n",
    "\n",
    "# upload hg38 annotation files for analysis\n",
    "hg38_df = pd.read_table('/path/to/annotation_files/NCBI_RefSeq_hg38_merge_parsed_sortByNameCoord.bed',header=None)\n",
    "hg38_df.columns = ['chrom','start', 'end','gene','feature','strand']\n",
    "\n",
    "# import RNAPET bed files with gene starts and ends\n",
    "K562_RNAPET_cyt = pd.read_table('/path/to/annotation_files/K562_ENCODE_RNAPET_cytosol_hg38_CrossMap.bed',header=None)\n",
    "K562_RNAPET_cyt.columns = ['chrom','start','end','ID','score','strand','start2','end2','zero','number','size','loc']\n",
    "K562_RNAPET_chr = pd.read_table('/path/to/annotation_files/K562_ENCODE_RNAPET_chromatin_hg38_CrossMap.bed',header=None)\n",
    "K562_RNAPET_chr.columns = ['chrom','start','end','ID','score','strand','start2','end2','zero','number','size','loc']\n",
    "\n",
    "# merge cytoplasm and chromatin RNAPET bed files\n",
    "K562_RNAPET_all = pd.concat([K562_RNAPET_cyt,K562_RNAPET_chr])\n",
    "\n",
    "# install splice sites from K562 intron files\n",
    "# NOTE: the intron stringency annotation files were made using the script intronCoord_stringency_from_RNAseq.py\n",
    "# and the thresholds indicated in the Methods. These files can be can be made for any cell line of interest \n",
    "# using a short-read Illumina RNA-seq BAM file and the script intronCoord_stringency_from_RNAseq.py\n",
    "K562_medium_intronFile = open('/path/to/annotation_files/K562_intronCoords_mediumStringency.txt') # get intron coordinates\n",
    "K562_medium_spliceSites = human_spliceSites(K562_medium_intronFile) # get splice sites\n",
    "\n",
    "# K562 -polyA dataset for removing unannotated poly(A) sites\n",
    "no_tail_bamFile = pybedtools.BedTool('/path/to/K562_4sUchr_ONT_no_tailing_hg38_minimap2_uniq_sort.bam')\n",
    "\n",
    "# upload alignment files for processing - K562 cells poly(A)\n",
    "K562_1_bamFile = pybedtools.BedTool('/path/to/K562_4sUchr_ONT_1_hg38_minimap2_uniq_sort.bam')\n",
    "K562_2_bamFile = pybedtools.BedTool('/path/to/K562_4sUchr_ONT_2_hg38_minimap2_uniq_sort.bam')\n",
    "K562_3_bamFile = pybedtools.BedTool('/path/to/K562_4sUchr_ONT_3_hg38_minimap2_uniq_sort.bam')\n",
    "\n",
    "# upload alignment files for processing - K562 cells poly(A) DMSO or PlaB\n",
    "K562_DMSO_1_bamFile = pybedtools.BedTool('/path/to/K562_ONT_DMSO_1_hg38_minimap2_uniq_sort.bam')\n",
    "K562_DMSO_2_bamFile = pybedtools.BedTool('/path/to/K562_ONT_DMSO_2_hg38_minimap2_uniq_sort.bam')\n",
    "K562_PlaB_1_bamFile = pybedtools.BedTool('/path/to/K562_ONT_PlaB_1_hg38_minimap2_uniq_sort.bam')\n",
    "K562_PlaB_2_bamFile = pybedtools.BedTool('/path/to/K562_ONT_PlaB_2_hg38_minimap2_uniq_sort.bam')\n",
    "\n",
    "# upload alignment files for processing - K562 cells poly(I)\n",
    "K562_4_bamFile = pybedtools.BedTool('/path/to/K562_4sUchr_ONT_4_hg38_minimap2_uniq_sort.bam')\n",
    "K562_5a_bamFile = pybedtools.BedTool('/path/to/K562_4sUchr_ONT_5a_hg38_minimap2_uniq_sort.bam')\n",
    "K562_5b_bamFile = pybedtools.BedTool('/path/to/K562_4sUchr_ONT_5b_hg38_minimap2_uniq_sort.bam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect reads that will be discarded from distance spliced analysis (K562 cells)\n",
    "\n",
    "# create a bed file with all regions that may not be representative of a transcription position\n",
    "K562_discarded_features = get_discarded_features_wiRNAPET_wiNoPolyA_bedtool(hg38_df, polyA_window, ss_window_upstream, ss_window_downstream, K562_RNAPET_all, RNAPET_window, no_tail_bamFile)\n",
    "\n",
    "# remove reads that have 3' ends within the bed file for discarded regions\n",
    "K562_1_discarded_reads = get_discarded_reads(K562_1_bamFile,K562_discarded_features)\n",
    "K562_2_discarded_reads = get_discarded_reads(K562_2_bamFile,K562_discarded_features)\n",
    "K562_3_discarded_reads = get_discarded_reads(K562_3_bamFile,K562_discarded_features)\n",
    "K562_4_discarded_reads = get_discarded_reads(K562_4_bamFile,K562_discarded_features)\n",
    "K562_5a_discarded_reads = get_discarded_reads(K562_5a_bamFile,K562_discarded_features)\n",
    "K562_5b_discarded_reads = get_discarded_reads(K562_5b_bamFile,K562_discarded_features)\n",
    "K562_DMSO_1_discarded_reads = get_discarded_reads(K562_DMSO_1_bamFile,K562_discarded_features)\n",
    "K562_DMSO_2_discarded_reads = get_discarded_reads(K562_DMSO_2_bamFile,K562_discarded_features)\n",
    "K562_PlaB_1_discarded_reads = get_discarded_reads(K562_PlaB_1_bamFile,K562_discarded_features)\n",
    "K562_PlaB_2_discarded_reads = get_discarded_reads(K562_PlaB_2_bamFile,K562_discarded_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get splice dataframes for plotting (after discarding unwanted reads) (K562 cells)\n",
    "K562_1_splice_df = get_discarded_splice_df(K562_1_bamFile, K562_1_discarded_reads, K562_medium_spliceSites, min_overlap, read_overhang, max_softclip)\n",
    "K562_2_splice_df = get_discarded_splice_df(K562_2_bamFile, K562_2_discarded_reads, K562_medium_spliceSites, min_overlap, read_overhang, max_softclip)\n",
    "K562_3_splice_df = get_discarded_splice_df(K562_3_bamFile, K562_3_discarded_reads, K562_medium_spliceSites, min_overlap, read_overhang, max_softclip)\n",
    "K562_4_splice_df = get_discarded_splice_df(K562_4_bamFile, K562_4_discarded_reads, K562_medium_spliceSites, min_overlap, read_overhang, max_softclip)\n",
    "K562_5a_splice_df = get_discarded_splice_df(K562_5a_bamFile, K562_5a_discarded_reads, K562_medium_spliceSites, min_overlap, read_overhang, max_softclip)\n",
    "K562_5b_splice_df = get_discarded_splice_df(K562_5b_bamFile, K562_5b_discarded_reads, K562_medium_spliceSites, min_overlap, read_overhang, max_softclip)\n",
    "K562_DMSO_1_splice_df = get_discarded_splice_df(K562_DMSO_1_bamFile, K562_DMSO_1_discarded_reads, K562_medium_spliceSites, min_overlap, read_overhang, max_softclip)\n",
    "K562_DMSO_2_splice_df = get_discarded_splice_df(K562_DMSO_2_bamFile, K562_DMSO_2_discarded_reads, K562_medium_spliceSites, min_overlap, read_overhang, max_softclip)\n",
    "K562_PlaB_1_splice_df = get_discarded_splice_df(K562_PlaB_1_bamFile, K562_PlaB_1_discarded_reads, K562_medium_spliceSites, min_overlap, read_overhang, max_softclip)\n",
    "K562_PlaB_2_splice_df = get_discarded_splice_df(K562_PlaB_2_bamFile, K562_PlaB_2_discarded_reads, K562_medium_spliceSites, min_overlap, read_overhang, max_softclip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save splice dataframes to file (to use again later for plotting) (K562 cells)\n",
    "K562_1_splice_df.to_csv('/path/to/K562_1_hg38_medIntrons_discarded_splice_df.txt', sep='\\t', index=False, header=True)\n",
    "K562_2_splice_df.to_csv('/path/to/K562_2_hg38_medIntrons_discarded_splice_df.txt', sep='\\t', index=False, header=True)\n",
    "K562_3_splice_df.to_csv('/path/to/K562_3_hg38_medIntrons_discarded_splice_df.txt', sep='\\t', index=False, header=True)\n",
    "K562_4_splice_df.to_csv('/path/to/K562_4_hg38_medIntrons_discarded_splice_df.txt', sep='\\t', index=False, header=True)\n",
    "K562_5a_splice_df.to_csv('/path/to/K562_5a_hg38_medIntrons_discarded_splice_df.txt', sep='\\t', index=False, header=True)\n",
    "K562_5b_splice_df.to_csv('/path/to/K562_5b_hg38_medIntrons_discarded_splice_df.txt', sep='\\t', index=False, header=True)\n",
    "K562_DMSO_1_splice_df.to_csv('/path/to/K562_DMSO_1_hg38_medIntrons_discarded_splice_df.txt', sep='\\t', index=False, header=True)\n",
    "K562_DMSO_2_splice_df.to_csv('/path/to/K562_DMSO_2_hg38_medIntrons_discarded_splice_df.txt', sep='\\t', index=False, header=True)\n",
    "K562_PlaB_1_splice_df.to_csv('/path/to/K562_PlaB_1_hg38_medIntrons_discarded_splice_df.txt', sep='\\t', index=False, header=True)\n",
    "K562_PlaB_2_splice_df.to_csv('/path/to/K562_PlaB_2_hg38_medIntrons_discarded_splice_df.txt', sep='\\t', index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lymphoblast samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install splice sites from BL1184 intron files\n",
    "GM12878_medium_intronFile = open('/path/to/annotation_files/GM12878_ENCSR000AEE_intronCoords_mediumStringency.txt') # get intron coordinates\n",
    "GM12878_medium_spliceSites = human_spliceSites(GM12878_medium_intronFile) # get splice sites\n",
    "\n",
    "# upload alignment files for processing - K562 cells poly(I)\n",
    "BL1184_1_bamFile = pybedtools.BedTool('/path/to/BL1184_4sUchr_ONT_1_hg38_minimap2_uniq_sort.bam')\n",
    "BL1184_2_bamFile = pybedtools.BedTool('/path/to/BL1184_4sUchr_ONT_2_hg38_minimap2_uniq_sort.bam')\n",
    "\n",
    "# remove reads that have 3' ends within the bed file for discarded regions\n",
    "BL1184_1_discarded_reads = get_discarded_reads(BL1184_1_bamFile,K562_discarded_features)\n",
    "BL1184_2_discarded_reads = get_discarded_reads(BL1184_2_bamFile,K562_discarded_features)\n",
    "\n",
    "# get splice dataframes for plotting (after discarding unwanted reads) (K562 cells)\n",
    "BL1184_1_splice_df = get_discarded_splice_df(BL1184_1_bamFile, BL1184_1_discarded_reads, GM12878_medium_spliceSites, min_overlap, read_overhang, max_softclip)\n",
    "BL1184_2_splice_df = get_discarded_splice_df(BL1184_2_bamFile, BL1184_2_discarded_reads, GM12878_medium_spliceSites, min_overlap, read_overhang, max_softclip)\n",
    "\n",
    "# save splice dataframes to file (to use again later for plotting) (K562 cells)\n",
    "BL1184_1_splice_df.to_csv('/path/to/BL1184_1_hg38_medIntrons_discarded_splice_df.txt', sep='\\t', index=False, header=True)\n",
    "BL1184_2_splice_df.to_csv('/path/to/BL1184_2_hg38_medIntrons_discarded_splice_df.txt', sep='\\t', index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drosophila samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare a bedtool file features for intersecting with read ends (S2)\n",
    "\n",
    "# upload dm6 annotation files for analysis\n",
    "dm6_df = pd.read_table('/path/to/annotation_files/dm6_RefSeq_merge_parsed_sortByNameCoord.bed',header=None)\n",
    "dm6_df.columns = ['chrom','start', 'end','gene','feature','strand']\n",
    "dm6_df['chrom'] = 'chr'+dm6_df['chrom']\n",
    "\n",
    "# install splice sites from K562 intron files\n",
    "S2_medium_intronFile = open('/path/to/annotation_files/S2_intronCoords_mediumStringency.txt') # get intron coordinates\n",
    "S2_medium_spliceSites = drosophila_spliceSites(S2_medium_intronFile) # get splice sites\n",
    "\n",
    "# upload alignment files for processing (S2 cells)\n",
    "S2_1a_bamFile = pybedtools.BedTool('/path/to/S2_4sUchr_ONT_1a_dm6_minimap2_uniq_sort.bam')\n",
    "S2_1b_bamFile = pybedtools.BedTool('/path/to/S2_4sUchr_ONT_1b_dm6_minimap2_uniq_sort.bam')\n",
    "S2_2_bamFile = pybedtools.BedTool('/path/to/S2_4sUchr_ONT_2_dm6_minimap2_uniq_sort.bam')\n",
    "S2_3_bamFile = pybedtools.BedTool('/path/to/S2_4sUchr_ONT_3_dm6_minimap2_uniq_sort.bam')\n",
    "S2_DMSO_1_bamFile = pybedtools.BedTool('/path/to/S2_ONT_DMSO_1_dm6_minimap2_uniq_sort.bam')\n",
    "S2_DMSO_2_bamFile = pybedtools.BedTool('/path/to/S2_ONT_DMSO_1_dm6_minimap2_uniq_sort.bam')\n",
    "S2_PlaB_1a_bamFile = pybedtools.BedTool('/path/to/S2_ONT_PlaB_1a_dm6_minimap2_uniq_sort.bam')\n",
    "S2_PlaB_1b_bamFile = pybedtools.BedTool('/path/to/S2_ONT_PlaB_1b_dm6_minimap2_uniq_sort.bam')\n",
    "S2_PlaB_2_bamFile = pybedtools.BedTool('/path/to/S2_ONT_PlaB_2_dm6_minimap2_uniq_sort.bam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect reads that will be discarded from the distance spliced analysis (S2)\n",
    "\n",
    "# create a bed file with all regions that may not be representative of a transcription position\n",
    "dm6_discarded_features = get_discarded_features_woRNAPET_bedtool(dm6_df, polyA_window, ss_window_upstream, ss_window_downstream)\n",
    "\n",
    "# remove reads that have 3' ends within the bed file for discarded regions\n",
    "S2_1a_discarded_reads = get_discarded_reads(S2_1a_bamFile,dm6_discarded_features)\n",
    "S2_1b_discarded_reads = get_discarded_reads(S2_1b_bamFile,dm6_discarded_features)\n",
    "S2_2_discarded_reads = get_discarded_reads(S2_2_bamFile,dm6_discarded_features)\n",
    "S2_3_discarded_reads = get_discarded_reads(S2_3_bamFile,dm6_discarded_features)\n",
    "S2_DMSO_1_discarded_reads = get_discarded_reads(S2_DMSO_1_bamFile,dm6_discarded_features)\n",
    "S2_DMSO_2_discarded_reads = get_discarded_reads(S2_DMSO_2_bamFile,dm6_discarded_features)\n",
    "S2_PlaB_1a_discarded_reads = get_discarded_reads(S2_PlaB_1a_bamFile,dm6_discarded_features)\n",
    "S2_PlaB_1b_discarded_reads = get_discarded_reads(S2_PlaB_1b_bamFile,dm6_discarded_features)\n",
    "S2_PlaB_2_discarded_reads = get_discarded_reads(S2_PlaB_2_bamFile,dm6_discarded_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare splicing dataframe for plotting (S2)\n",
    "\n",
    "# get dataframe that discards unwanted reads\n",
    "S2_1a_splice_df = get_discarded_splice_df(S2_1a_bamFile, S2_1a_discarded_reads, S2_medium_spliceSites, min_overlap, read_overhang, max_softclip)\n",
    "S2_1b_splice_df = get_discarded_splice_df(S2_1b_bamFile, S2_1b_discarded_reads, S2_medium_spliceSites, min_overlap, read_overhang, max_softclip)\n",
    "S2_2_splice_df = get_discarded_splice_df(S2_2_bamFile, S2_2_discarded_reads, S2_medium_spliceSites, min_overlap, read_overhang, max_softclip)\n",
    "S2_3_splice_df = get_discarded_splice_df(S2_3_bamFile, S2_3_discarded_reads, S2_medium_spliceSites, min_overlap, read_overhang, max_softclip)\n",
    "S2_DMSO_1_splice_df = get_discarded_splice_df(S2_DMSO_1_bamFile, S2_DMSO_1_discarded_reads, S2_medium_spliceSites, min_overlap, read_overhang, max_softclip)\n",
    "S2_DMSO_2_splice_df = get_discarded_splice_df(S2_DMSO_2_bamFile, S2_DMSO_2_discarded_reads, S2_medium_spliceSites, min_overlap, read_overhang, max_softclip)\n",
    "S2_PlaB_1a_splice_df = get_discarded_splice_df(S2_PlaB_1a_bamFile, S2_PlaB_1a_discarded_reads, S2_medium_spliceSites, min_overlap, read_overhang, max_softclip)\n",
    "S2_PlaB_1b_splice_df = get_discarded_splice_df(S2_PlaB_1b_bamFile, S2_PlaB_1b_discarded_reads, S2_medium_spliceSites, min_overlap, read_overhang, max_softclip)\n",
    "S2_PlaB_2_splice_df = get_discarded_splice_df(S2_PlaB_2_bamFile, S2_PlaB_2_discarded_reads, S2_medium_spliceSites, min_overlap, read_overhang, max_softclip)\n",
    "\n",
    "# save splice dataframes to file (to use again later for plotting) (K562 cells)\n",
    "S2_1a_splice_df.to_csv('/path/to/S2_1a_dm6_medIntrons_discarded_splice_df.txt', sep='\\t', index=False, header=True)\n",
    "S2_1b_splice_df.to_csv('/path/to/S2_1b_dm6_medIntrons_discarded_splice_df.txt', sep='\\t', index=False, header=True)\n",
    "S2_2_splice_df.to_csv('/path/to/S2_2_dm6_medIntrons_discarded_splice_df.txt', sep='\\t', index=False, header=True)\n",
    "S2_3_splice_df.to_csv('/path/to/S2_3_dm6_medIntrons_discarded_splice_df.txt', sep='\\t', index=False, header=True)\n",
    "S2_DMSO_1_splice_df.to_csv('/path/to/S2_DMSO_1_dm6_medIntrons_discarded_splice_df.txt', sep='\\t', index=False, header=True)\n",
    "S2_DMSO_2_splice_df.to_csv('/path/to/S2_DMSO_2_dm6_medIntrons_discarded_splice_df.txt', sep='\\t', index=False, header=True)\n",
    "S2_PlaB_1a_splice_df.to_csv('/path/to/S2_PlaB_1a_dm6_medIntrons_discarded_splice_df.txt', sep='\\t', index=False, header=True)\n",
    "S2_PlaB_1b_splice_df.to_csv('/path/to/S2_PlaB_1b_dm6_medIntrons_discarded_splice_df.txt', sep='\\t', index=False, header=True)\n",
    "S2_PlaB_2_splice_df.to_csv('/path/to/S2_PlaB_2_dm6_medIntrons_discarded_splice_df.txt', sep='\\t', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
